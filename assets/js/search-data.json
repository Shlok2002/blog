{
  
    
        "post0": {
            "title": "ELSS Funds",
            "content": "Background . As a responsible citizen of India, one who is able and pays personal taxes, imagine a scenario where you get reasonable returns on your investments and reduce your tax outgo at the same time. One may say this is an ideal scenario, but don’t be misled. Luckily, there is an investment vehicle available to all investors with the above-mentioned dual benefits. This unique investment product is an ELSS or Equity Linked Savings Scheme. . What are ELSS Funds? . An Equity Linked Saving Scheme (ELSS) is an open-ended equity mutual fund that invests primarily in equities and equity-related products. They are a particular category of mutual funds that qualify for tax deductions under Section 80C of the Income Tax Act, 1961. As a result, they are popularly known as tax saving mutual funds. . Features Specific to ELSS Funds . Lock-in Period: Most tax-saving investments have a lock-in period. A Public Provident Fund (PPF) has a lock-in period of 15 years. An FD may have a tenure anywhere between 5 to 8 years. ELSS Funds have a lock-in period of 3 years. This tenure is relatively shorter than other instruments and maybe a lucrative option for investors. Two investment options are available: Almost all ELSS funds offer a growth option, where there is no distribution of dividends and an IDCW, Income distribution cum capital withdrawal option, which has a regular distribution of dividends to its unitholders. No investment cap: There is no upper limit on how much you can invest in a financial year. You can invest as much as you want based on your budget and financial goals. However, you can avail of tax-saving benefits on ELSS investments up to Rs. 1.5 lakh every year. . Reasons to Invest in ELSS (Besides Tax Benefits) . Inflation beating returns: Since ELSS funds invest in equity and equity-linked products, they have a high probability of beating inflation Diversification: An ELSS fund is an excellent addition to your long-term portfolio Systematic Investment Plan: The investor can use the SIP or Systematic Investment Plan to invest in ELSS. This also helps to better plan and execute your tax savings. When you invest in ELSS through a SIP, you stand a chance to earn reasonable returns and achieve investment discipline. . Many investors invest in Equity Linked Saving Scheme funds to save tax at the end of the financial year tax. This may not be considered a good strategy. Tax saving is an essential consideration for investing in these funds. But it must not be the primary reason to consider investing in them. Remember, these are equity-linked products and have a high risk. The best way to maximise the benefits of such funds is to invest with a long-term approach. So, identify your investment goals at the beginning of the year and invest accordingly through Systematic Investment Plans (SIPs). Investing steadily all year round can help reduce your exposure to market volatility and build wealth over time. . . | Tenure | At least 3 years | |:———————-:|:————————————–:| | Returns | Variable; depends on market conditions | | Safety/Risk | High Risk High Rewards | | Minimum investment | Variable, as low as ₹500 | . . FAQs . Who should invest in an Equity Linked Saving Scheme? . Anyone interested in an investment avenue that could yield reasonable long-term returns and provide tax-saving benefits can invest in ELSS funds. So, if you have long-term financial goals like retirement planning, buying a house or financing your child’s college education, these funds can be a suitable option. . How can I invest in an Equity Linked Saving Scheme fund? . These funds are managed by Asset Management Companies (AMCs). Compare the fund option of different AMCs and choose the one matching your investment needs. Create an account with a fund house and invest accordingly. Alternatively, you can approach your financial advisor for selecting the right ELSS for you. . What is a lock-in period? . A lock-in period is a duration you must remain invested in the fund. You cannot withdraw your investment during this period. In the Equity Linked Saving Scheme, the lock-in period is for three years. .",
            "url": "https://shlok2002.github.io/blog/finance/digital%20gold/2022/12/29/ELSS.html",
            "relUrl": "/finance/digital%20gold/2022/12/29/ELSS.html",
            "date": " • Dec 29, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Math for ML Engineers [Part 1]",
            "content": "Introduction . When working with Machine Learning projects, you will come across a wide variety of equations that you need to implement in code. Mathematical notations capture a concept so eloquently but unfamiliarity with them makes them obscure. . In this post, I’ll be explaining the most common math notations by connecting it with its analogous concept in Python. Once you learn them, you will be able to intuitively grasp the intention of an equation and be able to implement it in code. . 1N∑i=1N(yi−yi^)2 frac{1}{N} sum_{i=1}^{N} (y_i - hat{y_i})^2N1​i=1∑N​(yi​−yi​^​)2 . Indexing . xix_ixi​ . This symbol is taking the value at ith^{th}th index of a vector. . x = [10, 20, 30] i = 0 print(x[i]) # 10 . This can be extended for 2D vectors and so on. xijx_{ij}xij​ . x = [ [10, 20, 30], [40, 50, 60] ] i = 0 j = 1 print(x[i][j]) # 20 . Sigma . ∑i=1Nxi sum_{i=1}^{N} x_ii=1∑N​xi​ . This symbol finds the sum of all elements in a vector for a given range. Both lower and upper limits are inclusive. In Python, it is equivalent to looping over a vector from index 0 to index N-1. Notice how we’re using the previously explained xix_ixi​ symbol to get the value at index. . x = [1, 2, 3, 4, 5] result = 0 N = len(x) for i in range(N): result = result + x[i] print(result) . The above code can even be shortened using built-in functions in Python as . x = [1, 2, 3, 4, 5] result = sum(x) . Average . 1N∑i=1Nxi frac{1}{N} sum_{i=1}^{N} x_iN1​i=1∑N​xi​ . Here we reuse the sigma notation and divide by the number of elements to get an average. . x = [1, 2, 3, 4, 5] result = 0 N = len(x) for i in range(N): result = result + x[i] average = result / N print(average) . The above code can even be shortened in Python as . x = [1, 2, 3, 4, 5] result = sum(x) / len(x) . PI . ∏i=1Nxi prod_{i=1}^{N} x_ii=1∏N​xi​ . This symbol finds the product of all elements in a vector for a given range. In Python, it is equivalent to looping over a vector from index 0 to index N-1 and multiplying them. . x = [1, 2, 3, 4, 5] result = 1 N = len(x) for i in range(N): result = result * x[i] print(result) . Pipe . The pipe symbol can mean different things based on where it’s applied. . Absolute Value . ∥x∥ lVert x rVert∥x∥ . ∥y∥ lVert y rVert∥y∥ . This symbol denotes the absolute value of a number i.e. without a sign. . x = 10 y = -20 abs(x) # 10 abs(y) # 20 . . Norm of vector . ∥x∥ lVert x rVert∥x∥ . The norm is used to calculate the magnitude of a vector. In Python, this means squaring each element of an array, summing them and then taking the square root. . import math x = [1, 2, 3] math.sqrt(x[0]**2 + x[1]**2 + x[2]**2) . Belongs to . 3 ∈ X3 in X3 ∈ X . This symbol checks if an element is part of a set. In Python, this would be equivalent to . X = {1, 2, 3} 3 in X . Function . f:X→Yf: X rightarrow Yf:X→Y . This denotes a function which takes a domain X and maps it to range Y. In Python, it’s equivalent to taking a pool of values X, doing some operation on it to calculate pool of values Y. . def f(X): Y = ... return Y . You will encounter the following symbols in place of X and Y. Here are what they mean: . f:R→Rf: R rightarrow Rf:R→R . R means input and outputs are real numbers and can take any value (integer, float, irrational, rational). In Python, this is equivalent to any value except complex numbers. . import math x = 1 y = 2.5 z = math.pi . You will also encounter symbols such as . f:Rd→Rf: R^d rightarrow Rf:Rd→R . RdR^dRd means d-dimensional vector of real numbers. . Let’s assume d = 2. In Python, an example can be a function that takes 2-D array and returns it’s sum. It will be mapping a RdR^dRd to RRR . X = [1, 2] f = sum Y = f(X) . Tensors . Transpose . XTX^{ mathsf{T}}XT . This is basically exchanging the rows and columns. In Python, this would be equivalent to . import numpy as np X = [[1, 2, 3], [4, 5, 6]] np.transpose(X) . Output would be a list with exchanged rows and columns. . [[1, 4], [2, 5], [3, 6]] . Element wise multiplication . z=x⊙yz = x odot yz=x⊙y . It means multiplying the corresponding elements in two tensors. In Python, this would be equivalent to multiplying the corresponding elements in two lists. . import numpy as np x = [[1, 2], [3, 4]] y = [[2, 2], [2, 2]] z = np.multiply(x, y) . Output is . [[2, 4]], [[6, 8]] . Dot Product . xyxyxy . x⋅yx cdot yx⋅y . It gives the sum of the products of the corresponding entries of the two sequences of numbers. . x = [1, 2, 3] y = [4, 5, 6] dot = sum([i*j for i, j in zip(x, y)]) # 1*4 + 2*5 + 3*6 # 32 . Hat . x^ hat{x}x^ . The hat gives the unit vector. This means dividing each component in a vector by it’s length(norm). . import math x = [1, 2, 3] length = math.sqrt(sum([e**2 for e in x])) x_hat = [e/length for e in x] . This makes the magnitude of the vector 1 and only keeps the direction. . import math math.sqrt(sum([e**2 for e in x_hat])) # 1.0 . Exclamation . x!x!x! . This denotes the factorial of a number. It is the product of numbers starting from 1 to that number. In Python, it can be calculated as . x = 5 fact = 1 for i in range(x, 0, -1): fact = fact * i print(fact) . The same thing can also be calculated using built-in function. . import math x = 5 math.factorial(x) . The output is . # 5*4*3*2*1 120 .",
            "url": "https://shlok2002.github.io/blog/machine%20learning/mathematics/2022/12/26/math-for-programmers.html",
            "relUrl": "/machine%20learning/mathematics/2022/12/26/math-for-programmers.html",
            "date": " • Dec 26, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "IPO Investing",
            "content": "Introduction . Had you invested ₹10,000 in Infosys’ 1993 IPO, you would have a little over 2 crores today. A mere 100 shares would have made you a crorepati. The shares were offered at a price of ₹95 but started trading at a significant premium at 145 a share. The listing gain would have been mouthwatering for an average investor to cash out. It was only the disciplined investor who was rewarded over the long term. With IPOs flooding the equity markets, investors are spoilt for choice. Knowing which is the best IPO to buy can be tricky. Investors are on a quest to find the next Infosys. . What is an IPO? . An IPO is an offer in which a company decides to go public by registering itself and listing on the stock exchanges. There can be multiple reasons that a company decides to go public; these include but are not limited to . Raise money for CAPEX purposes | Raise money to prepay/repay outstanding debt (loans) | Facilitate current investors to exit the company | Going public in an IPO can provide companies with a tremendous amount of publicity | Companies may want the standing and gravitas that often come with being a public company, which may help them secure better terms from lenders | . How to analyse an IPO . Behind every IPO, there is a company that has a legitimate business. When you buy shares, you buy a part of that business. Analysing a business may be complex, but having a basic outline to analyse IPOs is a must for investors seeking to invest in them. Following are the things to take notice of while exploring IPOs . Type of Issue | Reason for IPO | Performance of the company | Subscription of the issue | . Type of Issue . When a company issues its shares to the public, there are two significant issues, one being Offer for Sale (OFS) and the other one being Fresh Issue. During an OFS, existing company shareholders sell their shares, and no proceeds go to the company. On the other hand, a fresh issue results in all proceeds going to the company. These proceeds are further used to finance the post-IPO plans of the company. . Reason for IPO . One can get an excellent idea about the company, its business model, and the reasons for its IPO from the Red Herring Prospectus. The Draft Red Herring Prospectus, or DRHP, is filed by a company to SEBI when it intends to raise public money by selling company shares to investors. DRHP also elaborates how the company plans to use the funds raised and the possible risks for investors. Thus, investors must go through the DRHP before investing in an IPO. . Performance of the Company . The DHRP also has a dedicated section for performance-related matters. It has the company’s previous income statements, balance sheets, and cash flow statements. These can be used to evaluate the financial health of the company as well as make an informed decision before investing in the company. . Subscription of the Issue . An IPO window is usually open between 4-7 days. This is the duration where investors can bid for the shares. Every IPO has a certain quota reserved for different categories of investors. These divisions are based on the total application amount. Retail investors have an application amount of under ₹2,00,000 (2 lakhs). HNI or High Net Individuals are applications greater than ₹2 lakh, and QIB or Qualified Institutional Buyers are Fund houses, Marquee Investment Companies, pension funds, etc. A retail investor can look for the subscription of QIBs as a crude indication of the success of the IPO. . Bottom Line . The stock market is all about timing – when you enter and exit the market. Sometimes, the timing is correct during the IPO; sometimes, it’s better to wait. Make a decision depending on how much risk can you take and how good the fundamentals of the business are concerning its valuation. Be sceptical. When it comes to the IPO market, a suspicious and informed investor is likely to fare better. . . FAQs . How can one apply through the HNI category? . To apply via the HNI category, one has to id for shares totalling more than ₹2,00,000. This can be done via your broker. . What is the shareholder quota in an IPO? . In some public issues, the company going public keeps a special reservation for existing shareholders of the group or holding company. If you apply for the IPO in the shareholder category, the likelihood of allotment can be higher since most other applicants apply in the retail category. You need to hold 1 share of the parent company to be eligible for the shareholder quota. . What is ASBA? . Applications Supported by Blocked Amount (ASBA) is a method developed by SEBI to block the funds for Initial Public Offer (IPO), Rights issue, Follow-on Public Offer (FPO) etc., applications. In ASBA, an IPO applicant’s bank account doesn’t get debited until they receive the allotment of shares. .",
            "url": "https://shlok2002.github.io/blog/finance/investment%20101/2022/12/26/IPO.html",
            "relUrl": "/finance/investment%20101/2022/12/26/IPO.html",
            "date": " • Dec 26, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Market Basket Analysis",
            "content": "Dataset . The dataset is publicly available from the Kaggle website. It contains the Transactions data from a bakery from 30/10/2016 to 09/04/2017. The data belongs to a bakery called &quot;The Bread Basket&quot; that serves coffee, bread, muffin, cookies and so on. It is located in the historic center of Edinburgh. . Understanding MBA . Market basket analysis (MBA), also known as association-rule mining, is a useful method of discovering customer purchasing patterns by extracting associations or co-occurrences from stores&#39; transactional databases (Chen et al., 2005). It is a modelling technique based upon the theory that if you buy a certain group of items, you are more (or less) likely to buy another group of items. For example, if you are in a supermarket and you buy a loaf of Bread, you are more likely to buy a packet of Butter at the same time than somebody who didn&#39;t buy the Bread. Another example, if you are buying a XiaoMi Power Bank in an online store, you are more likely to also buy a carrying case to go with the power bank. Amazon knows this well from the transaction data of its millions of customers and thus recommends a case to you as seen below: . . The set of items a customer buys is known as an itemset, and MBA tries to identify relationships from the purchases of itemset. The output of MBA consists of a series of product association rules. From the transaction data extracted from the shopping carts of online retailers or the point of sales system of retail stores, we can use MBA to extract interesting association rules between products. For example, if customers buy product A they also tend to buy product B. . Typically we can extract the relationship between products in the form of a rule, an example of association rule: . IF {bread} THEN {butter}. . In this example, if customers buy Bread they also tend to buy Butter. Some people often link products with high association to &quot;complementary goods&quot;. In Economics 101, complementary good or service is consumed or used in conjunction with another good or service. Usually, the complementary good has little to no value when consumed alone, but when combined with another good or service, it adds to the overall value of the offering. For example a car and petrol. It would be of little value to buy petrol without owning a car. Complementary goods often have a negative cross-price elasticity of demand coefficient (Farnham, 2014). However, it is worth pointing out that, while complementary goods tend to have high association, not all products with high association rules are complementary goods. In MBA, we are more interested in product-pairs with high association rules i.e. products that are frequently purchased together. For example, in a retail store, MBA findings may show that Barbie dolls and candy are frequently purchased together, even though they are not technically complementary goods. In short, complementary goods are fairly obvious and common sense, but MBA seeks to uncover product associations that may not be so obvious and straighforward. In doing so, it is attempting to convert the abstract consumer tastes and preferences into association rules that are more insightful and actionable, from business perspective. . . Applications . There are many real-life applications of MBA: . Recommendation engine – showing related products as &quot;Customers Who Bought This Item Also Bought&quot; or “Frequently bought together” (as shown in the Amazon example above). It can also be applied to recommend videos and news article by analyzing the videos or news articles that are often watched or read together in a user session. | Cross-sell / bundle products – selling associated products as a &quot;bundle&quot; instead of individual items. For example, transaction data may show that customers often buy a new phone with screen protector together. Phone retailers can then package new phone with high-margin screen protector together and sell them as a bundle, thereby increasing their sales. | Arrangement of items in retail stores – associated items can be placed closer to each other, thereby invoking &quot;impulse buying&quot;. For example it may be uncovered that customers who buy Barbie dolls also buy candy at the same time. Thus retailers can place high-margin candy near Barbie doll display, thereby tempting customers to buy them together. | Detecting fraud – identifying related actions whenever a fraudulent transaction is performed. For example, in a fraudulent insurance claim for stolen vehicle, it may be analyzed (from historical data) that claimant frequently report the incident a few days late (action 1) and often refuse to cooperate with insurer on investigation (action 2). Insurers can identify these red flags once certain behaviours or actions are displayed by the claimants. | . . Case Study . For simplicity we are analyzing only 2 items – Bread and Butter. We want to know if there is any evidence that suggests that buying Bread leads to buying Butter. . Problem Statament: Is the purchase of Bread leads to the purchase of Butter? Hypothesis: There is significant evidence to show that buying Bread leads to buying Butter. . Bread =&gt; Butter . Antecedent =&gt; Consequent . Let&#39;s take the example of a supermarket which generates 1,000 transactions monthly, of which Bread was purchased in 150 transactions, Butter in 130 transactions, and both together in 50 transactions. . In set theory it can be represented as Bread only – 100, Butter only – 80, Bread and Butter – 50, as shown in the Venn diagram below: . . Analysis and Findings . We can use MBA to extract the association rule between Bread and Butter. There are three metrics or criteria to evaluate the strength or quality of an association rule, which are support, confidence and lift. . 1. Support . Support measures the percentage of transactions containing a particular combination of items relative to the total number of transactions. In our example, this is the percentage of transactions where both Bread and Butter are bought together. We need to calculate this to know if this combination of items is significant or negligible? Generally, we want a high percentage i.e. high support in order to make sure it is a useful relationship. Typically, we will set a threshold, for example we will only look at a combination if more than 1% of transactions have this combination. . Support (antecedent (Bread) and consequent (Butter)) = Number of transactions having both items / Total transactions . . Result: The support value of 5% means 5% of all transactions have this combination of Bread and Butter bought together. Since the value is above the threshold of 1%, it shows there is indeed support for this association and thus satisfy the first criteria. . . 2. Confidence . Confidence measures the probability of finding a particular combination of items whenever antecedent is bought. In probability terms, confidence is the conditional probability of the consequent given the antecedent and is represented as P (consequent / antecedent). In our example, it is the probability of both Bread and Butter being bought together whenever Bread is bought. Typically, we may set a threshold, say we want this combination to occur at least 25% of times when Bread is bought. . Confidence (antecedent i.e. Bread and consequent i.e. Butter) = P (Consequent (Butter) is bought GIVEN antecedent (Bread) is bought) . . Result: The confidence value of 33.3% is above the threshold of 25%, indicating we can be confident that Butter will be bought whenever Bread is bought, and thus satisfy the second criteria. . . 3. Lift . Lift is a metric to determine how much the purchase of antecedent influences the purchase of consequent. In our example, we want to know whether the purchase of Butter is independent of the purchase of Bread (or) is the purchase of Butter happening due to the purchase of Bread? In probability terms, we want to know which is higher, P (Butter) or P (Butter / Bread)? If the purchase of Butter is influenced by the purchase of Bread, then P (Butter / Bread) will be higher than P (Butter), or in other words, the ratio of P (Butter / Bread) over P (Butter) will be higher than 1. . . Result: The lift value of 2.56 is greater than 1, it shows that the purchase of Butter is indeed influenced by the purchase of Bread rather than Butter&#39;s purchase being independent of Bread. The lift value of 2.56 also means that Bread&#39;s purchase lifts the Butter&#39;s purchase by 2.56 times. . . Conclusion . Based on the findings above, we can justify our initial hypothesis as we . a) Have the support of 5% transactions for Bread and Butter in the same basket b) Have 33.3% confidence that Butter sales happen whenever Bread is purchased. c) Knows the lift in Butter&#39;s sales is 2.56 times more, whenever Bread is purchased than when Butter is purchased alone. . Therefore, we can conclude that there is indeed evidence to suggest that the purchase of Bread leads to the purchase of Butter. This is a valuable insight to guide management&#39;s decision-making. For example, managers of retail stores could start placing bread and butter close to each other, knowing that customers are highly likely to &quot;impulsively&quot; purchase them together, thereby increasing the store&#39;s revenue. . Implementation in Python . Importing libraries . %matplotlib inline !pip install mlxtend import numpy as np import pandas as pd import matplotlib.pyplot as plt from mlxtend.frequent_patterns import apriori from mlxtend.frequent_patterns import association_rules . Requirement already satisfied: mlxtend in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (0.21.0) Requirement already satisfied: scikit-learn&gt;=1.0.2 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.0.2) Requirement already satisfied: matplotlib&gt;=3.0.0 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (3.5.2) Requirement already satisfied: pandas&gt;=0.24.2 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.4.4) Requirement already satisfied: scipy&gt;=1.2.1 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.9.1) Requirement already satisfied: numpy&gt;=1.16.2 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.21.5) Requirement already satisfied: joblib&gt;=0.13.2 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.1.0) Requirement already satisfied: setuptools in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (63.4.1) Requirement already satisfied: fonttools&gt;=4.22.0 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from matplotlib&gt;=3.0.0-&gt;mlxtend) (4.25.0) Requirement already satisfied: pillow&gt;=6.2.0 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from matplotlib&gt;=3.0.0-&gt;mlxtend) (9.2.0) Requirement already satisfied: cycler&gt;=0.10 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from matplotlib&gt;=3.0.0-&gt;mlxtend) (0.11.0) Requirement already satisfied: kiwisolver&gt;=1.0.1 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from matplotlib&gt;=3.0.0-&gt;mlxtend) (1.4.2) Requirement already satisfied: packaging&gt;=20.0 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from matplotlib&gt;=3.0.0-&gt;mlxtend) (21.3) Requirement already satisfied: pyparsing&gt;=2.2.1 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from matplotlib&gt;=3.0.0-&gt;mlxtend) (3.0.9) Requirement already satisfied: python-dateutil&gt;=2.7 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from matplotlib&gt;=3.0.0-&gt;mlxtend) (2.8.2) Requirement already satisfied: pytz&gt;=2020.1 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from pandas&gt;=0.24.2-&gt;mlxtend) (2022.1) Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn&gt;=1.0.2-&gt;mlxtend) (2.2.0) Requirement already satisfied: six&gt;=1.5 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib&gt;=3.0.0-&gt;mlxtend) (1.16.0) . . Load Data . bread = pd.read_csv(&quot;BreadBasket_DMS.csv&quot;) bread.head(10) . Date Time Transaction Item . 0 2016-10-30 | 09:58:11 | 1 | Bread | . 1 2016-10-30 | 10:05:34 | 2 | Scandinavian | . 2 2016-10-30 | 10:05:34 | 2 | Scandinavian | . 3 2016-10-30 | 10:07:57 | 3 | Hot chocolate | . 4 2016-10-30 | 10:07:57 | 3 | Jam | . 5 2016-10-30 | 10:07:57 | 3 | Cookies | . 6 2016-10-30 | 10:08:41 | 4 | Muffin | . 7 2016-10-30 | 10:13:03 | 5 | Coffee | . 8 2016-10-30 | 10:13:03 | 5 | Pastry | . 9 2016-10-30 | 10:13:03 | 5 | Bread | . bread.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 21293 entries, 0 to 21292 Data columns (total 4 columns): # Column Non-Null Count Dtype -- -- 0 Date 21293 non-null object 1 Time 21293 non-null object 2 Transaction 21293 non-null int64 3 Item 21293 non-null object dtypes: int64(1), object(3) memory usage: 665.5+ KB . . Note: There are 21,293 rows and 4 columns in the dataframe. Date and Time columns are encoded in &#8217;object&#8217; instead of Datetime, but fortunately there is a Transaction column which helps to identify each transaction. Item column contains the individual items in that transaction. For example, Transaction No. 3 contains items of &quot;Hot chocolate&quot;, &quot;Jam&quot;, and &quot;Cookies&quot; which are all transacted in the same time i.e 10.07.57 on 2016-10-30. . Checking for missing values . bread.isnull().sum() . Date 0 Time 0 Transaction 0 Item 0 dtype: int64 . missing_value = [&quot;NaN&quot;, &quot;NONE&quot;, &quot;None&quot;, &quot;Nan&quot;, &quot;nan&quot;, &quot;nil&quot;, &quot;none&quot;] print(&quot;There are {0} missing values in the dataframe.&quot;.format(len(bread[bread.Item.isin(missing_value)]))) bread[bread.Item.isin(missing_value)].head(10) . There are 786 missing values in the dataframe. . Date Time Transaction Item . 26 2016-10-30 | 10:27:21 | 11 | NONE | . 38 2016-10-30 | 10:34:36 | 15 | NONE | . 39 2016-10-30 | 10:34:36 | 15 | NONE | . 66 2016-10-30 | 11:05:30 | 29 | NONE | . 80 2016-10-30 | 11:37:10 | 37 | NONE | . 85 2016-10-30 | 11:55:51 | 40 | NONE | . 126 2016-10-30 | 13:02:04 | 59 | NONE | . 140 2016-10-30 | 13:37:25 | 65 | NONE | . 149 2016-10-30 | 13:46:48 | 67 | NONE | . 167 2016-10-30 | 14:32:26 | 75 | NONE | . . Note: While there is no empty cell in the dataframe, a check using the popular missing value shows that there are 786 rows with &quot;NONE&quot; in the column Item. Since the items are not recorded, we will have to remove these rows. . bread = bread.drop(bread[bread.Item == &quot;NONE&quot;].index) print(&quot;Number of rows:{0}&quot;.format(len(bread))) bread.head(10) . Number of rows:20507 . Date Time Transaction Item . 0 2016-10-30 | 09:58:11 | 1 | Bread | . 1 2016-10-30 | 10:05:34 | 2 | Scandinavian | . 2 2016-10-30 | 10:05:34 | 2 | Scandinavian | . 3 2016-10-30 | 10:07:57 | 3 | Hot chocolate | . 4 2016-10-30 | 10:07:57 | 3 | Jam | . 5 2016-10-30 | 10:07:57 | 3 | Cookies | . 6 2016-10-30 | 10:08:41 | 4 | Muffin | . 7 2016-10-30 | 10:13:03 | 5 | Coffee | . 8 2016-10-30 | 10:13:03 | 5 | Pastry | . 9 2016-10-30 | 10:13:03 | 5 | Bread | . . Note: After removing the missing values, the number of rows left is 20,507 (original 21,293 minus 786 missing) . Convert to DatetimeIndex . bread[&#39;Datetime&#39;] = pd.to_datetime(bread[&#39;Date&#39;]+&#39; &#39;+bread[&#39;Time&#39;]) bread = bread[[&quot;Datetime&quot;, &quot;Transaction&quot;, &quot;Item&quot;]]. set_index(&quot;Datetime&quot;) bread.head(10) . Transaction Item . Datetime . 2016-10-30 09:58:11 1 | Bread | . 2016-10-30 10:05:34 2 | Scandinavian | . 2016-10-30 10:05:34 2 | Scandinavian | . 2016-10-30 10:07:57 3 | Hot chocolate | . 2016-10-30 10:07:57 3 | Jam | . 2016-10-30 10:07:57 3 | Cookies | . 2016-10-30 10:08:41 4 | Muffin | . 2016-10-30 10:13:03 5 | Coffee | . 2016-10-30 10:13:03 5 | Pastry | . 2016-10-30 10:13:03 5 | Bread | . Quick stats . total_items = len(bread) total_days = len(np.unique(bread.index.date)) total_months = len(np.unique(bread.index.month)) average_items = total_items / total_days unique_items = bread.Item.unique().size print(&quot;There are {} unique items sold by the Bakery&quot;.format(unique_items)) print(&quot;Total {} items sold in {} days throughout {} months&quot;.format(total_items, total_days, total_months)) print(&quot;With an average of {} items sold daily&quot;.format(average_items)) . There are 94 unique items sold by the Bakery Total 20507 items sold in 159 days throughout 7 months With an average of 128.9748427672956 items sold daily . . Note: We have combined the Date and Time columns into a single Datetime column, convert it into datetime64 type, and then set it as DatetimeIndex. This will make it easier to plot the time series charts later on. Also, a quick look at the data shows that the Bakery sold an average of 129 items daily. . Visualisation . bread.Item.value_counts(normalize=True)[:10] . Coffee 0.266787 Bread 0.162140 Tea 0.069976 Cake 0.049983 Pastry 0.041742 Sandwich 0.037597 Medialuna 0.030039 Hot chocolate 0.028771 Cookies 0.026332 Brownie 0.018481 Name: Item, dtype: float64 . bread.Item.value_counts(normalize=True)[:10].plot(kind=&quot;bar&quot;, title=&quot;Percentage of Sales by Item&quot;).set(xlabel=&quot;Item&quot;,ylabel=&quot;Percentage&quot;) . [Text(0.5, 0, &#39;Item&#39;), Text(0, 0.5, &#39;Percentage&#39;)] . bread.Item.value_counts()[:10].plot(kind=&quot;bar&quot;, title=&quot;Total Number of Sales by Item&quot;).set(xlabel=&quot;Item&quot;, ylabel=&quot;Total Number&quot;) . [Text(0.5, 0, &#39;Item&#39;), Text(0, 0.5, &#39;Total Number&#39;)] . . Note: From the bar charts above, it is clear that Coffee (26.7%) is the best-selling item in the bakery, follow by Bread (16.2%) and Tea (7.0%). . bread[&quot;Item&quot;].resample(&quot;D&quot;).count().plot(figsize=(12,5), grid=True, title=&quot;Total Number of Items Sold by Date&quot;).set(xlabel=&quot;Date&quot;,ylabel=&quot;Total Number of Items Sold&quot;) . [Text(0.5, 0, &#39;Date&#39;), Text(0, 0.5, &#39;Total Number of Items Sold&#39;)] . . Note: Total Number of Items Sold by Date fluctuates a lot thoughout the 159 days of data . bread[&quot;Item&quot;].resample(&quot;M&quot;).count() . Datetime 2016-10-31 369 2016-11-30 4436 2016-12-31 3339 2017-01-31 3356 2017-02-28 3906 2017-03-31 3944 2017-04-30 1157 Freq: M, Name: Item, dtype: int64 . bread[&quot;Item&quot;].resample(&quot;M&quot;).count().plot(figsize=(12,5), grid=True, title=&quot;Total Number by Items Sold by Month&quot;).set(xlabel=&quot;Date&quot;,ylabel=&quot;Total Number of Items Sold&quot;) . [Text(0.5, 0, &#39;Date&#39;), Text(0, 0.5, &#39;Total Number of Items Sold&#39;)] . . Note: Given that the beginning month (October 2016) and ending month (April 2017) are not full month, the total number of items sold by month for the five full month between November 2016 to March 2017 does not fluctuate too much . # For Datetimeindex, the day of the week with Monday=0, Sunday=6, thereby +1 to become Monday=1, Sunday=7 bread[&quot;Hour&quot;] = bread.index.hour bread[&quot;Weekday&quot;] = bread.index.weekday + 1 bread.head(10) . Transaction Item Hour Weekday . Datetime . 2016-10-30 09:58:11 1 | Bread | 9 | 7 | . 2016-10-30 10:05:34 2 | Scandinavian | 10 | 7 | . 2016-10-30 10:05:34 2 | Scandinavian | 10 | 7 | . 2016-10-30 10:07:57 3 | Hot chocolate | 10 | 7 | . 2016-10-30 10:07:57 3 | Jam | 10 | 7 | . 2016-10-30 10:07:57 3 | Cookies | 10 | 7 | . 2016-10-30 10:08:41 4 | Muffin | 10 | 7 | . 2016-10-30 10:13:03 5 | Coffee | 10 | 7 | . 2016-10-30 10:13:03 5 | Pastry | 10 | 7 | . 2016-10-30 10:13:03 5 | Bread | 10 | 7 | . bread_groupby_hour = bread.groupby(&quot;Hour&quot;).agg({&quot;Item&quot;: lambda item: item.count()/total_days}) bread_groupby_hour . Item . Hour . 1 0.006289 | . 7 0.150943 | . 8 4.056604 | . 9 12.364780 | . 10 16.767296 | . 11 19.509434 | . 12 17.949686 | . 13 16.459119 | . 14 16.603774 | . 15 13.301887 | . 16 8.446541 | . 17 2.314465 | . 18 0.515723 | . 19 0.301887 | . 20 0.138365 | . 21 0.018868 | . 22 0.050314 | . 23 0.018868 | . bread_groupby_hour.plot(y=&quot;Item&quot;, figsize=(12,5), title=&quot;Average Number by Items Sold by Hour of the Day&quot;).set(xlabel=&quot;Hour of the Day (24 hour time)&quot;, ylabel=&quot;Average Number of Items Sold&quot;) . [Text(0.5, 0, &#39;Hour of the Day (24 hour time)&#39;), Text(0, 0.5, &#39;Average Number of Items Sold&#39;)] . . Note: Sales starts to pick up from 8am, till the busiest hour of the day at 11am, then slowly drops till the late afternoon. It can be observed that most of the sales transactions took place during the lunch hours of the day . bread_groupby_weekday = bread.groupby(&quot;Weekday&quot;).agg({&quot;Item&quot;: lambda item: item.count()}) bread_groupby_weekday . Item . Weekday . 1 2324 | . 2 2392 | . 3 2321 | . 4 2646 | . 5 3124 | . 6 4605 | . 7 3095 | . # in order to calculate the average items per weekday import datetime daterange = pd.date_range(datetime.date(2016, 10, 30), datetime.date(2017, 4, 9)) monday = 0 tuesday = 0 wednesday = 0 thursday = 0 friday = 0 saturday = 0 sunday = 0 for day in np.unique(bread.index.date): if day.isoweekday() == 1: monday += 1 elif day.isoweekday() == 2: tuesday += 1 elif day.isoweekday() == 3: wednesday += 1 elif day.isoweekday() == 4: thursday += 1 elif day.isoweekday() == 5: friday += 1 elif day.isoweekday() == 6: saturday += 1 elif day.isoweekday() == 7: sunday += 1 all_weekdays = monday + tuesday + wednesday + thursday + friday + saturday + sunday print(&quot;monday = {0}, tuesday = {1}, wednesday = {2}, thursday = {3}, friday = {4}, saturday = {5}, sunday = {6}, total = {7}&quot;.format(monday, tuesday, wednesday, thursday, friday, saturday, sunday, all_weekdays)) . monday = 21, tuesday = 23, wednesday = 23, thursday = 23, friday = 23, saturday = 23, sunday = 23, total = 159 . conditions = [ (bread_groupby_weekday.index == 1), (bread_groupby_weekday.index == 2), (bread_groupby_weekday.index == 3), (bread_groupby_weekday.index == 4), (bread_groupby_weekday.index == 5), (bread_groupby_weekday.index == 6), (bread_groupby_weekday.index == 7)] choices = [bread_groupby_weekday.Item/21, bread_groupby_weekday.Item/23, bread_groupby_weekday.Item/23, bread_groupby_weekday.Item/23, bread_groupby_weekday.Item/23, bread_groupby_weekday.Item/23, bread_groupby_weekday.Item/23] bread_groupby_weekday[&quot;Average&quot;] = np.select(conditions, choices, default=0) bread_groupby_weekday . Item Average . Weekday . 1 2324 | 110.666667 | . 2 2392 | 104.000000 | . 3 2321 | 100.913043 | . 4 2646 | 115.043478 | . 5 3124 | 135.826087 | . 6 4605 | 200.217391 | . 7 3095 | 134.565217 | . bread_groupby_weekday.plot(y=&quot;Average&quot;, figsize=(12,5), title=&quot;Average Number by Items Sold by Day of the Week&quot;).set(xlabel=&quot;Day of the Week (1=Monday, 7=Sunday)&quot;, ylabel=&quot;Average Number of Items Sold&quot;) . [Text(0.5, 0, &#39;Day of the Week (1=Monday, 7=Sunday)&#39;), Text(0, 0.5, &#39;Average Number of Items Sold&#39;)] . . Note: Saturday is the busiest day of the week with the highest sales (~200 items) while Wednesday is the quietest day with the lowest sales (~101 items). This is an interesting insight, the owner of the Bakery should launch some promotion activities to boost up sales in the middle of the week when sales are slowest. . The Apriori function in the MLxtend library expects data in a one-hot encoded pandas DataFrame. This means that all the data for a transaction must be included in one row and the items must be one-hot encoded. Example below: . Coffee Cake Bread Cookie Muffin Tea Milk Juice Sandwich . 0 | 0 | 1 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | . 1 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | . 2 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | . 3 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | . 4 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . Therefore, we&#39;ll need to group the bread dataframe by Transaction and Item and display the count of items. Then we need to consolidate the items into one transaction per row with each item one-hot encoded. . df = bread.groupby([&quot;Transaction&quot;,&quot;Item&quot;]).size().reset_index(name=&quot;Count&quot;) df.head() . Transaction Item Count . 0 1 | Bread | 1 | . 1 2 | Scandinavian | 2 | . 2 3 | Cookies | 1 | . 3 3 | Hot chocolate | 1 | . 4 3 | Jam | 1 | . basket = (df.groupby([&#39;Transaction&#39;, &#39;Item&#39;])[&#39;Count&#39;] .sum().unstack().reset_index().fillna(0) .set_index(&#39;Transaction&#39;)) basket.head() . Item Adjustment Afternoon with the baker Alfajores Argentina Night Art Tray Bacon Baguette Bakewell Bare Popcorn Basket ... The BART The Nomad Tiffin Toast Truffles Tshirt Valentine&#39;s card Vegan Feast Vegan mincepie Victorian Sponge . Transaction . 1 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 2 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 3 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 4 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 5 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 5 rows × 94 columns . basket[basket.Coffee == 4].iloc[:,14:28] . Item Brownie Cake Caramel bites Cherry me Dried fruit Chicken Stew Chicken sand Chimichurri Oil Chocolates Christmas common Coffee Coffee granules Coke Cookies Crepes . Transaction . 6560 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 4.0 | 0.0 | 0.0 | 1.0 | 0.0 | . 6850 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 4.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 6887 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 4.0 | 0.0 | 0.0 | 0.0 | 0.0 | . . Important: At this stage, the one-hot encoded table shows the count of items purchased as result. If you observe the portion of the table above, in Transaction 6887, the cell value for Coffee is &quot;4.0&quot; because there were 4 coffee purchased in this transaction. However, this is not important for us and we need to convert this value into 1. . def encode_units(x): if x &lt;= 0: return 0 if x &gt;= 1: return 1 . basket_sets = basket.applymap(encode_units) basket_sets.head() . Item Adjustment Afternoon with the baker Alfajores Argentina Night Art Tray Bacon Baguette Bakewell Bare Popcorn Basket ... The BART The Nomad Tiffin Toast Truffles Tshirt Valentine&#39;s card Vegan Feast Vegan mincepie Victorian Sponge . Transaction . 1 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 3 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 rows × 94 columns . basket_sets[basket_sets.Coffee == 1].iloc[3142:3145,14:28] . Item Brownie Cake Caramel bites Cherry me Dried fruit Chicken Stew Chicken sand Chimichurri Oil Chocolates Christmas common Coffee Coffee granules Coke Cookies Crepes . Transaction . 6884 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | . 6885 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | . 6887 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | . . Note: After applying the encoding function, for the same Transaction 6887, the cell value for Coffee has become &quot;1&quot; which is what we need for the Apriori function. . Generate Frequent Itemsets . Now, we are ready to generate the frequent item sets. We will set the minimum-support threshold at 1% . frequent_itemsets = apriori(basket_sets, min_support=0.01, use_colnames=True) . /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:111: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type warnings.warn( . . Generate Association Rules . The final step is to generate the rules with their corresponding support, confidence and lift. We will set the minimum threshold for lift at 1 and then sort the result by descending confidence value. . rules = association_rules(frequent_itemsets, metric=&quot;lift&quot;, min_threshold=1) rules.sort_values(&quot;confidence&quot;, ascending = False, inplace = True) rules.head(10) . antecedents consequents antecedent support consequent support support confidence lift leverage conviction . 31 (Toast) | (Coffee) | 0.033597 | 0.478394 | 0.023666 | 0.704403 | 1.472431 | 0.007593 | 1.764582 | . 28 (Spanish Brunch) | (Coffee) | 0.018172 | 0.478394 | 0.010882 | 0.598837 | 1.251766 | 0.002189 | 1.300235 | . 19 (Medialuna) | (Coffee) | 0.061807 | 0.478394 | 0.035182 | 0.569231 | 1.189878 | 0.005614 | 1.210871 | . 23 (Pastry) | (Coffee) | 0.086107 | 0.478394 | 0.047544 | 0.552147 | 1.154168 | 0.006351 | 1.164682 | . 1 (Alfajores) | (Coffee) | 0.036344 | 0.478394 | 0.019651 | 0.540698 | 1.130235 | 0.002264 | 1.135648 | . 17 (Juice) | (Coffee) | 0.038563 | 0.478394 | 0.020602 | 0.534247 | 1.116750 | 0.002154 | 1.119919 | . 25 (Sandwich) | (Coffee) | 0.071844 | 0.478394 | 0.038246 | 0.532353 | 1.112792 | 0.003877 | 1.115384 | . 7 (Cake) | (Coffee) | 0.103856 | 0.478394 | 0.054728 | 0.526958 | 1.101515 | 0.005044 | 1.102664 | . 27 (Scone) | (Coffee) | 0.034548 | 0.478394 | 0.018067 | 0.522936 | 1.093107 | 0.001539 | 1.093366 | . 13 (Cookies) | (Coffee) | 0.054411 | 0.478394 | 0.028209 | 0.518447 | 1.083723 | 0.002179 | 1.083174 | . Interpretation and Implications . The output above shows the Top 10 itemsets sorted by confidence value and all itemsets have support value over 1% and lift value over 1. The first itemset shows the association rule &quot;if Toast then Coffee&quot; with support value at 0.023666 means nearly 2.4% of all transactions have this combination of Toast and Coffee bought together. We also have 70% confidence that Coffee sales happen whenever a Toast is purchased. The lift value of 1.47 (greater than 1) shows that the purchase of Coffee is indeed influenced by the purchase of Toast rather than Coffee&#39;s purchase being independent of Toast. The lift value of 1.47 means that Toast&#39;s purchase lifts the Coffee&#39;s purchase by 1.47 times. . Therefore, we can conclude that there is indeed evidence to suggest that the purchase of Toast leads to the purchase of Coffee. The owner of the bakery &quot;The Bread Basket&quot; should consider bundling Toast and Cofee together as a Breakfast Set or Lunch Set, the staff in the store should also be trained to cross-sell Coffee to customers who purchase Toast, knowing that they are more likely to purchase them together, thereby increasing the store&#39;s revenue. . References . Chen, Y.L., Tang, K., Shen, R. J. &amp; Hu, Y. H. (2005). Market basket analysis in a multiple store environment. Decision Support Systems, 40(2), 339-354. | Farnham, P. G. (2014). Economics for Managers (3rd ed.). Essex, England: Pearson Education Limited. | Kaur, M. &amp; Kang, S. (2016). Market Basket Analysis: Identify the Changing Trends of Market Data Using Association Rule Mining. Procedia Computer Science, 85, 78-85. | Li, S. (2017, September 25), A Gentle Introduction on Market Basket Analysis — Association Rules. Towards Data Science. Retrieved from https://towardsdatascience.com/a-gentle-introduction-on-market-basket-analysis-association-rules-fa4b986a40ce | Moffitt, C. (2017, July 3). Introduction to Market Basket Analysis in Python. Practical Business Python. Retrieved from http://pbpython.com/market-basket-analysis.html | Rajaram, M. (2018, October 11). Market Basket Explained. Indium Software. Retrieved from https://indiumsoftware.com/blog/market-basket-explained/ | Wong, G. (2018, October 12). MBA For Breakfast or also known as the Market Basket Analysis. Towards Data Science. Retrieved from https://towardsdatascience.com/mba-for-breakfast-4c18164ef82b |",
            "url": "https://shlok2002.github.io/blog/machine%20learning/analytics/2022/12/25/Market-Basket-Analysis.html",
            "relUrl": "/machine%20learning/analytics/2022/12/25/Market-Basket-Analysis.html",
            "date": " • Dec 25, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Network Analytics",
            "content": "Topics covered . Calculating correlations between asset classes | Heatmap visualisation using seaborn | Network analysis and visualisation using NetworkX | Minimum spanning trees | Interactive visualisations using Plotly | . Introduction . Network analysis is becoming an ever increasingly popular method to analyse and visualise complex relationships in data in an intuitive way. . One interesting application of network analytics is visualising relationships between asset classes in the finance industry. We are always told that equities and bonds tend to move in opposite directions and certain assets such as gold and the Japanese Yen are &#39;safe-haven&#39; assets and therefore behave in similar ways. But what does that actually look like and are there any other interesting relationships between asset classes? Networks can be a great way to convey this information at a high level and help understand broad market dynamics. . Information on the correlations between asset classes can be particularly useful for investors wanting to diversify their portfolio. Most people understand that portfolio risk can be mitigated by diversification, however, this may not always be the case. For instance if you &#39;diversified&#39; your portfolio by investing in two different stocks which are strongly correlated with each other (i.e. if stock A goes up 2% then stock B also goes up 2%) then the overall risk of the portfolio has not been reduced as if there is a negative factor affecting stock A then it is also likely to affect stock B and both prices will trend downwards. Therefore, diversification can only be realistically achieved by investing in assets which are uncorrelated with each other. Good explanations of this phenomenon can be found at Quantdare and the Investors Chronicle. . In this post I will explain how we can visualise asset correlations as an interactive network diagram which allows the user to gain a high level overview of the relationships between asset classes. From this information they can identify areas of risk but also opportunities for diversification of their portfolio. We will cover the basics of how to calculate correlations between asset price returns using numpy and pandas, using NetworkX to create a network graph and finally use Plotly to display the network as an interactive visualisation. . Library imports . numpy and pandas to read and manipulate the raw data | networkx to generate the network representation of the data and create some initial graph visualisations | matplotlib and seaborn for general visualisations and plot formatting | Plotly to create the final interactive visualisation | . import matplotlib.pyplot as plt import networkx as nx import numpy as np import pandas as pd import plotly.graph_objs as go import seaborn as sns from plotly.offline import init_notebook_mode # plotly offline mode init_notebook_mode(connected=True) . Load data . For this analysis we will use a dataset containing the daily adjusted closing prices of 39 major ETFs which represent different asset classes covering equities, bonds, currencies and commodities. The data covers a period of 4 years between November 2013 and November 2017. . raw_asset_prices_df = pd.read_csv(&quot;data/daily_asset_prices.csv&quot;, index_col=&quot;Date&quot;) # show first five rows raw_asset_prices_df.head() . Bonds Global Commodities DOW Emerg Markets EAFE Emerg Markets Bonds Pacifix ex Japan Germany Italy Japan ... Europe Pacific VXX Materials Energy Finance Tech Utilities ST Corp Bond CHF . Date . 2017-11-08 81.83 | 16.40 | 235.46 | 46.78 | 69.87 | 114.60 | 47.69 | 33.18 | 30.95 | 60.02 | ... | 58.20 | 72.77 | 33.53 | 58.70 | 69.82 | 26.25 | 64.01 | 55.70 | 104.96 | 94.5100 | . 2017-11-07 81.89 | 16.43 | 235.42 | 46.56 | 69.64 | 114.65 | 47.22 | 33.07 | 31.09 | 59.65 | ... | 58.17 | 72.20 | 33.52 | 58.64 | 70.16 | 26.38 | 63.66 | 55.66 | 105.01 | 94.5400 | . 2017-11-06 81.86 | 16.53 | 235.41 | 46.86 | 69.90 | 115.26 | 47.20 | 33.34 | 31.22 | 59.18 | ... | 58.67 | 71.98 | 33.34 | 58.58 | 70.25 | 26.75 | 63.63 | 55.00 | 105.00 | 94.7500 | . 2017-11-03 81.80 | 16.22 | 235.18 | 46.34 | 69.80 | 115.42 | 47.09 | 33.39 | 31.22 | 59.19 | ... | 58.58 | 71.88 | 33.66 | 58.83 | 68.68 | 26.78 | 63.49 | 55.21 | 105.00 | 94.4400 | . 2017-11-02 81.73 | 16.12 | 234.96 | 46.58 | 69.91 | 116.15 | 47.31 | 33.50 | 31.43 | 59.05 | ... | 58.69 | 71.89 | 33.71 | 58.86 | 68.48 | 26.89 | 62.99 | 55.01 | 105.04 | 94.6299 | . 5 rows × 39 columns . df_shape = raw_asset_prices_df.shape print(f&quot;There are {df_shape[0]} rows and {df_shape[1]} columns in the dataset&quot;) print( ( f&quot;Data time-period covers: {min(raw_asset_prices_df.index)} &quot; f&quot;to {max(raw_asset_prices_df.index)}&quot; ) ) . There are 1013 rows and 39 columns in the dataset Data time-period covers: 2013-11-01 to 2017-11-08 . . Note: We can see that the csv file of asset prices contains 39 different assets and 1013 records for each asset. The time-series is in reverse order (newest to oldest) and there are no missing datapoints in the dataset. . Calculate asset price correlations . Convert to log returns . Before calculating the correlation matrix, it is important to first normalise the dataset and convert the absolute asset prices into daily returns. In financial time-series it is common to make this transformation as investors are typically interested in returns on assets rather than their absolute prices. By normalising the data it allows us to compare the expected returns of two assets more easily. . log_returns_df = pd.DataFrame() # calculate log returns of each asset # loop through each column in dataframe and and calculate the daily log returns # add log returns column to new a dataframe for col in raw_asset_prices_df.columns: # dates are given in reverse order so need to set diff to -1. log_returns_df[col] = np.log(raw_asset_prices_df[col]).diff(-1) # check output of log returns dataframe log_returns_df.head() . Bonds Global Commodities DOW Emerg Markets EAFE Emerg Markets Bonds Pacifix ex Japan Germany Italy Japan ... Europe Pacific VXX Materials Energy Finance Tech Utilities ST Corp Bond CHF . Date . 2017-11-08 -0.000733 | -0.001828 | 0.000170 | 0.004714 | 0.003297 | -0.000436 | 0.009904 | 0.003321 | -0.004513 | 0.006184 | ... | 0.000516 | 0.007864 | 0.000298 | 0.001023 | -0.004858 | -0.004940 | 0.005483 | 0.000718 | -0.000476 | -0.000317 | . 2017-11-07 0.000366 | -0.006068 | 0.000042 | -0.006423 | -0.003727 | -0.005306 | 0.000424 | -0.008131 | -0.004173 | 0.007911 | ... | -0.008559 | 0.003052 | 0.005384 | 0.001024 | -0.001282 | -0.013928 | 0.000471 | 0.011929 | 0.000095 | -0.002219 | . 2017-11-06 0.000733 | 0.018932 | 0.000977 | 0.011159 | 0.001432 | -0.001387 | 0.002333 | -0.001499 | 0.000000 | -0.000169 | ... | 0.001535 | 0.001390 | -0.009552 | -0.004259 | 0.022602 | -0.001121 | 0.002203 | -0.003811 | 0.000000 | 0.003277 | . 2017-11-03 0.000856 | 0.006184 | 0.000936 | -0.005166 | -0.001575 | -0.006305 | -0.004661 | -0.003289 | -0.006704 | 0.002368 | ... | -0.001876 | -0.000139 | -0.001484 | -0.000510 | 0.002916 | -0.004099 | 0.007906 | 0.003629 | -0.000381 | -0.002009 | . 2017-11-02 0.000979 | 0.006223 | 0.003283 | 0.001289 | 0.003008 | 0.002759 | 0.005723 | 0.004488 | 0.009591 | 0.001186 | ... | 0.002559 | 0.002089 | -0.011210 | -0.007279 | -0.002916 | 0.009341 | 0.000476 | 0.003642 | 0.000000 | 0.004553 | . 5 rows × 39 columns . Calculate correlations matrix . To calculate the pairwise correlations between assets we can simply use the inbuilt pandas corr() function. . correlation_matrix = log_returns_df.corr() # show first five rows of the correlation matrix correlation_matrix.head() . Bonds Global Commodities DOW Emerg Markets EAFE Emerg Markets Bonds Pacifix ex Japan Germany Italy Japan ... Europe Pacific VXX Materials Energy Finance Tech Utilities ST Corp Bond CHF . Bonds Global 1.000000 | -0.086234 | -0.279161 | -0.069623 | -0.177521 | 0.296679 | -0.104739 | -0.188547 | -0.201014 | -0.159231 | ... | -0.181249 | -0.141707 | 0.222886 | -0.220603 | -0.198536 | -0.420264 | -0.197672 | 0.301774 | 0.598105 | 0.250142 | . Commodities -0.086234 | 1.000000 | 0.305137 | 0.428909 | 0.369637 | 0.313791 | 0.400316 | 0.283711 | 0.331083 | 0.250509 | ... | 0.367019 | 0.341089 | -0.224835 | 0.429541 | 0.677430 | 0.257454 | 0.225463 | 0.089290 | 0.028872 | 0.042324 | . DOW -0.279161 | 0.305137 | 1.000000 | 0.719260 | 0.793387 | 0.343817 | 0.688344 | 0.722882 | 0.666315 | 0.691672 | ... | 0.765251 | 0.769604 | -0.797538 | 0.817422 | 0.655544 | 0.874902 | 0.849271 | 0.395247 | -0.042967 | -0.172730 | . Emerg Markets -0.069623 | 0.428909 | 0.719260 | 1.000000 | 0.796425 | 0.580454 | 0.815049 | 0.697222 | 0.660268 | 0.638955 | ... | 0.763111 | 0.811155 | -0.668680 | 0.674630 | 0.607172 | 0.606749 | 0.686458 | 0.365031 | 0.123624 | -0.018461 | . EAFE -0.177521 | 0.369637 | 0.793387 | 0.796425 | 1.000000 | 0.466883 | 0.790699 | 0.884385 | 0.830052 | 0.785198 | ... | 0.949368 | 0.872972 | -0.721559 | 0.720030 | 0.610561 | 0.711714 | 0.725415 | 0.352270 | 0.050121 | 0.021760 | . 5 rows × 39 columns . Correlations Heatmap . The conventional way to visualise correlations is via a heatmap. Before developing the network visualisation, we will quickly create a heatmap of the correlation matrix to check the output of the correlation calculations and to gain a high level insight into some of the relationships present in the data. . Seaborn has a very useful function called clustermap which visualises the matrix as a heatmap but also clusters the ETFs so that ETFs which behave similarly are next to each other. Clustered heatmaps can be a useful way of visualising correlations between attributes in a dataset, especially if the data is highly dimensional as it automatically reorders attributes which are similar to each other into clusters. This makes the heatmap more structured and readable so it is easier to identify relationships between ETFs and which asset classes behave similarly. . display(HTML(&quot;&lt;h3&gt;Clustered Heatmap: Correlations between asset price returns&lt;/h3&gt;&quot;)) sns.clustermap(correlation_matrix, cmap=&quot;RdYlGn&quot;) plt.show() . Clustered Heatmap: Correlations between asset price returns . The heatmap is colour coded using a divergent colourscale where strong positive correlations (correlation = 1) are dark green, uncorrelated assets are yellow (correlation = 0) and negatively correlated assets are red (correlation = -1). . The clustered heatmap visualisation already gives a good picture of the data and tells an interesting story: . Broadly speaking, there are two major clusters of assets. These appear to be separated into equities and &quot;non-equity&quot; assets (e.g. bonds, currencies and precious metals). The heatmap shows that these two categories are generally negatively or non-correlated with each other which is expected as &#39;safe haven&#39; assets such as bonds, gold and currencies like the Japanese Yen tend to move in opposite directions to equities which are seen as a riskier asset class. | ETFs tracking Geographic regions which are close to each other are highly correlated with each other. For example, UK, Europe, Germany, Italy and France ETFs are highly correlated with each other, so are Japan, Pacific ex Japan and China ETFs | The VXX ETF is strongly negatively correlated with equities. | Network Visualisations . Heatmaps are useful, however, they can only convey one dimension of information (the magnitude of the correlation between two assets). As an investor wanting to make a decision on which asset classes to invest in, a heatmap still does not help answer important questions such as what the annualized returns and volatility of an asset class is. . We can use network graphs to investigate the initial findings from the heatmap further and visualise them in a more accessible way which encodes more information. . Networkx . Networkx is one of the most popular and useful Python libraries for analysing small/medium size networks. . In order to analyse the the correlations matrix as a network we first need to convert the correlations between assets to an edge list. This is a list containing information for each connection between each asset ETF in our data. This format requires the &#39;source&#39; node (ETF), the &#39;target&#39; node and the &#39;weight&#39; (correlation) of the link between the two. . Create edge list . edges = correlation_matrix.stack().reset_index() edges.columns = [&quot;asset_1&quot;, &quot;asset_2&quot;, &quot;correlation&quot;] # remove self correlations edges = edges.loc[edges[&quot;asset_1&quot;] != edges[&quot;asset_2&quot;]].copy() # show the first 5 rows of the edge list dataframe. edges.head() . asset_1 asset_2 correlation . 1 Bonds Global | Commodities | -0.086234 | . 2 Bonds Global | DOW | -0.279161 | . 3 Bonds Global | Emerg Markets | -0.069623 | . 4 Bonds Global | EAFE | -0.177521 | . 5 Bonds Global | Emerg Markets Bonds | 0.296679 | . Create graph from edge list . Now that we have an edge list we need to feed that into the networkx library to create a graph. Note that this network is undirected as the correlation between assets is the same in both directions. . G0 = nx.from_pandas_edgelist(edges, &quot;asset_1&quot;, &quot;asset_2&quot;, edge_attr=[&quot;correlation&quot;]) # print out the graph info # check number of nodes and degrees are as expected # (all should have degree = 38, i.e. average degree = 38) print(nx.info(G0)) . Graph with 39 nodes and 741 edges . Visualise the network . To visualise the graph we have just created, we can use a number of &#39;out-of-the-box&#39; layouts which can be drawn using networkx, for example: . circular_layout - Position nodes on a circle. | random_layout - Position nodes uniformly at random in the unit square. | spectral_layout - Position nodes using the eigenvectors of the graph Laplacian. | spring_layout - Position nodes using Fruchterman-Reingold force-directed algorithm. | . fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(20, 20)) # save different layout functions in a list layouts = [nx.circular_layout, nx.random_layout, nx.spring_layout, nx.spectral_layout] # plot each different layout for layout, ax in zip(layouts, axs.ravel()): nx.draw( G0, with_labels=True, node_size=700, node_color=&quot;#e1575c&quot;, edge_color=&quot;#363847&quot;, pos=layout(G0), ax=ax, ) ax.set_title(layout.__name__, fontsize=20, fontweight=&quot;bold&quot;) plt.show() . . Note: Whilst these visualisations may look cool, they are not very useful in their current form as all nodes have the same number of edges (links), and each edge looks the same so no useful information about the correlations between ETFs can be gained. . Improved network visualisation . The network visualisation can be improved in a number of ways by thinking about the sort of information which we are looking to uncover from this analysis. It is important to think about what questions we wish to answer from the data and then design the visualisation to gain the most insight for the question in hand. For the purposes of enhancing the visualisation, We will assume that the audience for this visualisation will be investors wanting to assess risk in their portfolio. Investors would want to identify which assets are correlated and uncorrelated with each other in order to assess the unsystematic risk in their portfolio. Therefore, from this visualisation the user would want to quickly understand: . which assets show strong/meaningful correlations (i.e. &gt;0.5) with each other | are these correlations positive or negative | which are the most/least &#39;connected&#39; assets. (i.e. which assets share the most/least strong correlations with other assets in the dataset) | which groups of assets behave similarly (i.e. which assets are correlated with the same type of other assets) | . With this information, an investor could identify if they held a number of assets which behave the same (increased risk) and identify assets which show very few correlations with assets currently held in the portfolio and investigate these as a potential opportunity for diversification. . For a first iteration to improve the network visualisation we can take the circular layout graph from above and make the following changes: . reduce the number of connections between nodes by adding a threshold value for the strength of correlation | introduce colour to signify positive or negative correlations | scale the edge thickness to indicate the magnitude of correlation | scale the size of nodes to indicate which assets have the greatest number of strong correlations with the rest of the assets in the dataset | . Remove edges below a threshold . # edges from the diagram threshold = 0.5 # create a new graph from edge list Gx = nx.from_pandas_edgelist(edges, &quot;asset_1&quot;, &quot;asset_2&quot;, edge_attr=[&quot;correlation&quot;]) # list to store edges to remove remove = [] # loop through edges in Gx and find correlations which are below the threshold for asset_1, asset_2 in Gx.edges(): corr = Gx[asset_1][asset_2][&quot;correlation&quot;] # add to remove node list if abs(corr) &lt; threshold if abs(corr) &lt; threshold: remove.append((asset_1, asset_2)) # remove edges contained in the remove list Gx.remove_edges_from(remove) print(str(len(remove)) + &quot; edges removed&quot;) . 530 edges removed . Create colour, edge thickness and node size features . def assign_colour(correlation): if correlation &lt;= 0: return &quot;#ffa09b&quot; # red else: return &quot;#9eccb7&quot; # green def assign_thickness(correlation, benchmark_thickness=2, scaling_factor=3): return benchmark_thickness * abs(correlation) ** scaling_factor def assign_node_size(degree, scaling_factor=50): return degree * scaling_factor # assign colours to edges depending on positive or negative correlation # assign edge thickness depending on magnitude of correlation edge_colours = [] edge_width = [] for key, value in nx.get_edge_attributes(Gx, &quot;correlation&quot;).items(): edge_colours.append(assign_colour(value)) edge_width.append(assign_thickness(value)) # assign node size depending on number of connections (degree) node_size = [] for key, value in dict(Gx.degree).items(): node_size.append(assign_node_size(value)) . Draw improved graph . sns.set(rc={&quot;figure.figsize&quot;: (9, 9)}) font_dict = {&quot;fontsize&quot;: 18} nx.draw( Gx, pos=nx.circular_layout(Gx), with_labels=True, node_size=node_size, node_color=&quot;#e1575c&quot;, edge_color=edge_colours, width=edge_width, ) plt.title(&quot;Asset price correlations&quot;, fontdict=font_dict) plt.show() . The network visualisation has been improved in four main ways: . less cluttered: we have removed edges with weak correlations and kept only the edges with significant (actionable) correlations | identify type of correlation: simple intuitive colour scheme to show positive (green) or negative (red) correlations | identify strength of correlation: we now are able to assess the relative strength of correlations between nodes, with prominence given to the correlations with the greatest magnitude | identify the most connected nodes: the size of the nodes has been adjusted to emphasise which nodes have the greatest number of strong correlations with other nodes in the network | . Looking at this network we could now quickly identify which assets are highly correlated and therefore may pose increased risk on the portfolio. The viewer could also identify and investigate further the assets with low degree of connectivity (smaller node size) as these are weakly correlated with the other assets in the sample and may provide an opportunity to diversify the portfolio. . The circular layout, however, does not group the nodes in a meaningful order, it just orders the nodes in the order in which they were created, therefore it is difficult to gain insight as to which assets are most similar to each other in terms of correlations to other nodes. We can improve this with a spring based layout using the &#39;Fruchterman-Reingold&#39; algorithm [2] which sets the positions of the nodes using a cost function which minimises the distances between strongly correlated nodes. This algorithm will therefore cluster the nodes which are strongly correlated with each other allowing the viewer to quickly identify groups of assets with similar properties. . nx.draw( Gx, pos=nx.fruchterman_reingold_layout(Gx), with_labels=True, node_size=node_size, node_color=&quot;#e1575c&quot;, edge_color=edge_colours, width=edge_width, ) plt.title(&quot;Asset price correlations - Fruchterman-Reingold layout&quot;, fontdict=font_dict) plt.show() . The Fruchterman Reingold layout has successfully grouped the assets into clusters of strongly correlated assets. As seen before in the heatmap visualisation, there are distinct clusters of assets which behave similarly to each other. There is a cluster containing bond ETFs, a cluster of precious metal ETFs (silver, gold, goldminers), a cluster of currencies (CHF, USD, Euro) and a large cluster for equities. . However, the main cluster of equities ETFs is still very cluttered as the nodes are very tightly packed and the node sizes and labels are overlapping making it difficult to make out. . As the layout now positions the nodes which are strongly correlated in space, it is no longer necessary to keep every single edge as it is implied that assets closer to each other in space are more strongly correlated. We can also convert the node sizes back to a consistent (smaller) size as the degree of each node is now meaningless. . Minimum spanning tree . It is common in financial networks to use a minimum spanning tree [3,4,5] to visualise networks. A minimum spanning tree reduces the edges down to a subset of edges which connects all the nodes together, without any cycles and with the minimum possible sum of edge weights (correlation value in this case). This essentially provides a skeleton of the graph, minimising the number of edges and reducing the clutter in the network graph. . Kruskal&#39;s algorithm is used to calculate the minimum spanning tree and is fairly intuitive. However, Networkx has an inbuilt function which calculates the minimum spanning tree for us. . # (after small correlations have been removed) mst = nx.minimum_spanning_tree(Gx) edge_colours = [] # assign edge colours for key, value in nx.get_edge_attributes(mst, &quot;correlation&quot;).items(): edge_colours.append(assign_colour(value)) # draw minimum spanning tree. Set node size and width to constant nx.draw( mst, with_labels=True, pos=nx.fruchterman_reingold_layout(mst), node_size=200, node_color=&quot;#e1575c&quot;, edge_color=edge_colours, width=1.2, ) # set title plt.title(&quot;Asset price correlations - Minimum Spanning Tree&quot;, fontdict=font_dict) plt.show() . The improved graph has made the clusters of nodes more readable by reducing the node size and reducing the number of edges in the graph. However, reducing the clutter was at the expense of conveying some information about the nodes such as nodes with the most strong correlations and their relative strengths. . Interactive visualisation . Finally, I will explore the use of interactive plotting libraries to enhance the user experience and alleviate some of the missing information issues with the use of informative tooltips. . Currently the network is very &#39;static&#39; and does not convey any information other than spacial relationships between strongly correlated assets. Although useful, this logically leads the viewer to ask more questions about the properties of each individual node in a cluster such as their historical returns and the nodes with which it is least correlated to. . One way to include such information about each node is to use an interactive graph with informative tooltips. This can be achieved using the Plotly[6] python library which offers a python api to create interactive javascript graphs built in d3.js. The following code uses the Plotly api to create a graph with the following features: . interactivity, such as zoom, to focus on clusters of nodes | tooltips which provides useful information about the node when the user hovers over it | node sizes proportional to the annualised returns of each asset | node colours to show asset positive or negative return over the dataset timeframe | . Plotly . The Python code required for Ploty graphs can be a little bit more involved than out of the box matplotlib or seaborn charts but allows for much more customisation. . The main benefit of using Plotly in this example is the use of tooltips. In these tooltips we can store lots of additional information about each ETF which we can access by hovering over the respective node in the graph. . There are obviously many different bits of information of use which we could incorporate into the tooltip. For this example I will add: . annualised returns of the asset class | annualised volatility of the asset class | the top and bottom 3 assets which the asset of interest is most/least strongly correlated with| | . Functions to get node information to populate tooltips . The following functions calculate the above quantities. It should be noted that Plotly tooltips are formatted using html. Therefore the input to the tooltip should be a string with the relevant html tags for any formatting that is required. . def convert_rankings_to_string(ranking): &quot;&quot;&quot; Concatenate list of nodes and correlations into a single html string (required format for the plotly tooltip) Inserts html &quot;&lt;br&gt;&quot; inbetween each item in order to add a new line in the tooltip &quot;&quot;&quot; s = &quot;&quot; for r in ranking: s += r + &quot;&lt;br&gt;&quot; return s def calculate_stats(returns=log_returns_df): &quot;&quot;&quot;calculate annualised returns and volatility for all ETFs Returns: tuple: Outputs the annualised volatility and returns as a list of floats (for use in assigning node colours and sizes) and also as a lists of formatted strings to be used in the tool tips. &quot;&quot;&quot; # log returns are additive, 252 trading days annualized_returns = list(np.mean(returns) * 252 * 100) annualized_volatility = [ np.std(returns[col] * 100) * (252 ** 0.5) for col in list(returns.columns) ] # create string for tooltip annualized_volatility_2dp = [ &quot;Annualized Volatility: &quot; &quot;%.1f&quot; % r + &quot;%&quot; for r in annualized_volatility ] annualized_returns_2dp = [ &quot;Annualized Returns: &quot; &quot;%.1f&quot; % r + &quot;%&quot; for r in annualized_returns ] return ( annualized_volatility, annualized_returns, annualized_volatility_2dp, annualized_returns_2dp, ) def get_top_and_bottom_three(df=correlation_matrix): &quot;&quot;&quot; get a list of the top 3 and bottom 3 most/least correlated assests for each node. Args: df (pd.DataFrame): pandas correlation matrix Returns: top_3_list (list): list of lists containing the top 3 correlations (name and value) bottom_3_list (list): list of lists containing the bottom three correlations (name and value) &quot;&quot;&quot; top_3_list = [] bottom_3_list = [] for col in df.columns: # exclude self correlation #reverse order of the list returned top_3 = list(np.argsort(abs(df[col]))[-4:-1][::-1]) # bottom 3 list is returned in correct order bottom_3 = list(np.argsort(abs(df[col]))[:3]) # get column index col_index = df.columns.get_loc(col) # find values based on index locations top_3_values = [df.index[x] + &quot;: %.2f&quot; % df.iloc[x, col_index] for x in top_3] bottom_3_values = [ df.index[x] + &quot;: %.2f&quot; % df.iloc[x, col_index] for x in bottom_3 ] top_3_list.append(convert_rankings_to_string(top_3_values)) bottom_3_list.append(convert_rankings_to_string(bottom_3_values)) return top_3_list, bottom_3_list . Function to generate coordinates . Plotly does not have an &#39;out-of-the-box&#39; network graph chart, therefore we need to &#39;imitate&#39; the network layout by plotting the data as a scatter plot which plots the graph nodes, and plot a &#39;line&#39; chart on top which draws the lines which connect each point. To achieve this we need a function which converts the Fruchterman Reingold coordinates calculated using networtx into an x and y series to create the scatter plot. We also need to store the x and y coordinates of the start and end of each edge which will be used to draw the &#39;line&#39; chart. . The function calculates the x and y coordinates for the scatter plot (Xnodes and Ynodes) and the coordinates of the starting and ending positions of the lines connecting nodes (Xedges, Yedges): . def get_coordinates(G=mst): &quot;&quot;&quot;Returns the positions of nodes and edges in a format for Plotly to draw the network &quot;&quot;&quot; # get list of node positions pos = nx.fruchterman_reingold_layout(mst) Xnodes = [pos[n][0] for n in mst.nodes()] Ynodes = [pos[n][1] for n in mst.nodes()] Xedges = [] Yedges = [] for e in mst.edges(): # x coordinates of the nodes defining the edge e Xedges.extend([pos[e[0]][0], pos[e[1]][0], None]) Yedges.extend([pos[e[0]][1], pos[e[1]][1], None]) return Xnodes, Ynodes, Xedges, Yedges . Plotly Graph Code . Now we can finally plot the network as an interactive Plotly visualisation. . First, we need to calculate all the quantities and concatenate them into a html string to be used as an input for the tooltip. Then we need to calculate the coordinates for the scatter and line plots and finally define the node color and size which depend on the direction and size of the annualised returns. . # make list of node labels. node_label = list(mst.nodes()) # calculate annualised returns, annualised volatility and round to 2dp annual_vol, annual_ret, annual_vol_2dp, annual_ret_2dp = calculate_stats() # get top and bottom 3 correlations for each node top_3_corrs, bottom_3_corrs = get_top_and_bottom_three() # create tooltip string by concatenating statistics description = [ f&quot;&lt;b&gt;{node}&lt;/b&gt;&quot; + &quot;&lt;br&gt;&quot; + annual_ret_2dp[index] + &quot;&lt;br&gt;&quot; + annual_vol_2dp[index] + &quot;&lt;br&gt;&lt;br&gt;Strongest correlations with: &quot; + &quot;&lt;br&gt;&quot; + top_3_corrs[index] + &quot;&lt;br&gt;Weakest correlations with: &quot; &quot;&lt;br&gt;&quot; + bottom_3_corrs[index] for index, node in enumerate(node_label) ] # get coordinates for nodes and edges Xnodes, Ynodes, Xedges, Yedges = get_coordinates() # assign node colour depending on positive or negative annualised returns node_colour = [assign_colour(i) for i in annual_ret] # assign node size based on annualised returns size (scaled by a factor) node_size = [abs(x) ** 0.5 * 5 for x in annual_ret] . To plot the network we define the scatter plot (tracer) and line plot (tracer_marker) series and define some cosmetic parameters which dictate the graph layout. . # edges tracer = go.Scatter( x=Xedges, y=Yedges, mode=&quot;lines&quot;, line=dict(color=&quot;#DCDCDC&quot;, width=1), hoverinfo=&quot;none&quot;, showlegend=False, ) # nodes tracer_marker = go.Scatter( x=Xnodes, y=Ynodes, mode=&quot;markers+text&quot;, textposition=&quot;top center&quot;, marker=dict(size=node_size, line=dict(width=1), color=node_colour), hoverinfo=&quot;text&quot;, hovertext=description, text=node_label, textfont=dict(size=7), showlegend=False, ) axis_style = dict( title=&quot;&quot;, titlefont=dict(size=20), showgrid=False, zeroline=False, showline=False, ticks=&quot;&quot;, showticklabels=False, ) layout = dict( title=&quot;Plotly - interactive minimum spanning tree&quot;, width=800, height=800, autosize=False, showlegend=False, xaxis=axis_style, yaxis=axis_style, hovermode=&quot;closest&quot;, plot_bgcolor=&quot;#fff&quot;, ) fig = go.Figure() fig.add_trace(tracer) fig.add_trace(tracer_marker) fig.update_layout(layout) fig.show() display( HTML( &quot;&quot;&quot; &lt;p&gt;Node sizes are proportional to the size of annualised returns.&lt;br&gt;Node colours signify positive or negative returns since beginning of the timeframe.&lt;/p&gt; &quot;&quot;&quot; ) ) . Node sizes are proportional to the size of annualised returns.Node colours signify positive or negative returns since beginning of the timeframe. . With this final network layout, we have summarised the most important information about the relationships between assets in the dataset. Users can quickly identify clusters of assets which are strongly correlated with each other, gauge the performance of the asset over the timeframe by looking at the node sizes and colours and can get more detailed information about each node by hovering over it. . Conclusion . In this post we have shown how to visualise a network of asset price correlations using the networkx python library. The &#39;out of the box&#39; networkx visualisations were iteratively improved to help the audience identify assets which behave similarly to other assets in the dataset. This was achieved by reducing redundant information in the network and using intuitive colour schemes, edge thickness and node thickness to convey information in a qualitative way. The functionality of the visualisation was further improved by the use of Plotly, an interactive graphing library, which allowed us to use tooltips to store more information about each node in the network without cluttering the visualisation. . Future Work . Further work could look at the rolling asset correlations over a shorter timeframe and see how these may have changed over time and how this then affects the network layout and clusters. This could help identify outliers or asset classes which are not behaving as &#39;normal&#39;. There are also many more interesting calculations which can be carried out on the network, such as working out which are the most important or influential nodes in the networks by using centrality measures [7]. . The post focused on how to visualise the network using networkx and Plotly, however, there are many other libraries and software which could have been used and are worth investigating: . Open Source Python Libraries . Graphviz | Pygraphviz | . Open Source Interactive Libraries . d3.js | . Network drawing Software . Gelphi Gelphi (https://gephi.org/) | . If you are interested in investigating network analytics in the financial industry in more detail, I would highly recommend checking out https://www.fnalab.com/ which is a commercial platform for financial network analytics. They have a free trial to their platform which has some very impressive network visualisations of the stock market but also financial transcations for fraud detection and many more applications. . References . [1] Networkx documentation: https://networkx.github.io/documentation/stable/reference/drawing.html [2] Fruchterman, T.M. and Reingold, E.M., 1991. Graph drawing by force-directed placement. 1991. Zitiert auf den, p.37. [3] Mantegna, R.N., 1999. Hierarchical structure in financial markets. The European Physical Journal B-Condensed Matter and Complex Systems, 11(1), pp.193-197. [4] Rešovský, M., Horváth, D., Gazda, V. and Siničáková, M., 2013. Minimum Spanning Tree Application in the Currency Market. Biatec, 21(7), pp.21-23. [5] Financial Network Analytics: https://www.fna.fi/ [6] Plotly: https://plot.ly/d3-js-for-python-and-pandas-charts/ [7] Wenyue Sun, Chuan Tian, Guang Yang, 2015, Network Analysis of the Stock Market .",
            "url": "https://shlok2002.github.io/blog/network/analytics/2022/12/24/Asset_Price_Network.html",
            "relUrl": "/network/analytics/2022/12/24/Asset_Price_Network.html",
            "date": " • Dec 24, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "Capital Markets and the Repo Rate",
            "content": "Background . For an economy to grow, that country’s fiscal and monetary policies should complement one another. For India, the growth story has just begun. Dubbed one of the fastest-growing Asian economies, the balance between the economic and fiscal policy is of utmost importance. The Indian government expects the Reserve Bank of India (RBI) to keep the economy running smoothly; if the monetary authority feels the economy is lagging, it slashes the repo rate to make borrowing money cheaper for individuals and businesses. This typically pushes up stock prices and rewards investors with better results. . In the early months of the COVID-19 pandemic, there was a rapid decline in economic activity, and the stock market came crashing down. The RBI responded by slashing rates to an all-time low- and fast forward 26 months later; stocks came storming back. But what happens when the RBI raises interest rates? . What is the Repo Rate? . Like any borrower, banks need to pay interest on their loans too. When a commercial bank needs money, it can borrow from the RBI. The Central Bank charges a rate for the loan called the Repo rate. Commercial banks also need to deposit collateral with the RBI to receive the loan. The banks can use collateral like government bonds and treasury bills. . One of the ways the RBI controls the constant rise in prices, also known as inflation, is through the Repo rate. Increasing the Repo rate makes borrowing more expensive for commercial banks. They transfer this extra cost of interest to their retail borrowers. The retail borrowers would have to pay more interest to borrow a loan from a commercial bank. That will limit the bank’s borrowers from taking out loans. The lesser funds the borrowers have, the lesser money in the market. As the money in the market reduces, so does the spending. That, in turn, reduces the cost of goods and services. . If RBI wants to increase spending, it cuts the REPO rate. The commercial banks will borrow more. They will then reduce interest rates for their retail borrowers. More loans will be taken, and there will be an increase in cash flow in the market. That will cause an increase in the growth of the economy. . The current repo rate is at 4.90% which is 90 basis points above the pandemic levels. The RBI hopes to curb inflation by sucking out the liquidity from the economy and promoting reduced spending. Experts believe that the repo rate could rise all the way up to 6% - 6.15%. . Increasing interest rates reduces the free cash that people have and spend on luxuries like travel, eating out, going to movies, etc. The entertainment industry is impacted to a certain extent by the increase in rates. . Relation between Stock Market &amp; Repo Rate . The stock market and interest rates have an inverse relationship; as we have seen earlier, once the RBI increases the repo rate, the amount of cash available in the market decreases. This means that companies also cut back on their spending on the expansion. This lack of expenditure causes a dip in its growth and will affect the profit and future cash flows. This may lead to a fall in stock prices. An increase in interest rates will increase savings and reduce the flow of capital to the economy. . On the other hand, a decrease in interest rates will increase capital flows to the stock market. This will increase the possibility of higher returns from the stock as the company can go high on the expansion spree. . The impact of these changes is not the same on all the sectors or companies. For example, the capital-intensive sectors like infrastructure, capital goods, etc., are more prone to these changes due to high capital or debt on the books of these companies. On the other hand, stocks of capital-light sectors like IT, FMCG, etc., have a lesser impact on these changes. . Conclusion . The RBI balances the inflation risk and growth in the economy by adjusting the repo rate. The Repo rate is one of the tools available to the central bank to control the money supply. Financial markets react sharply to any signs of such adjustments. As an investor, you should keep an eye on these. .",
            "url": "https://shlok2002.github.io/blog/finance/2022/12/23/Repo-rate.html",
            "relUrl": "/finance/2022/12/23/Repo-rate.html",
            "date": " • Dec 23, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "What is an NFT?",
            "content": "Background . Jack Dorsey sells his first tweet ever as an NFT for $2.9 million, read the headline of major business newspapers on 24th March 2021. A year later, Twitter is going private, all thanks to Elon Musk, in what is said to be the largest Leveraged buyout (LBO) ever. Both Jack Dorsey and Elon Musk are successful entrepreneurs who have voiced their support for the Blockchain Revolution. This revolution is not going away anytime soon! Let’s get back to the question, can you sell a tweet? How do you do it, and what is that N-F-T doing there in the headline? . What is an NFT? . NFT stands for Non-Fungible-Token; non-fungible means something that cannot be exchanged for an item because it is unique. In other words, you can exchange a ₹100 note for another ₹100 note as both have the same value associated with them. Another classic example is a cryptocurrency; 1 Bitcoin can be exchanged for another. Cryptocurrency is fungible, whereas NFTs are not. On the other hand, one piece of artwork is not equal to another; The Mona Lisa is not equal to a Van Gogh’s since both have unique properties. NFTs are tokens that live on a blockchain and represent ownership of unique items. Why do you need a blockchain to do this? Well, tracking a digital file is tricky, as it can be copied and distributed effortlessly. A blockchain comes in handy for ease of tracking ownership and for the value discovery of an asset. Let us take an example to cement our understanding. . Suppose you made a piece of digital art. You can create a .jpg or mint an NFT out of this. The NFT that represents your art contains information about it, such as . A unique fingerprint ID of the file (Hash) . | Token Name . | Token Symbol . | . This token is then stored on the blockchain, and you, the artist, become the owner. To sell the artwork, you create a transaction on the blockchain, and the blockchain makes sure that this information can never be tampered with. It also allows you to track the current owner if the artwork is traded further. In other words, it is a smart contract on the blockchain that stores the unique properties of the asset and keeps track of current and previous owners. . Specifics of an NFT . It is important to note that the artwork itself is not stored in the blockchain; only its attributes like hash, name and a link to the actual artwork are stored in the block. Also, one must keep in mind that you often do not get a physical copy of the original artwork and most of the time, anyone can download a physical copy for free. The NFT only represents proof of ownership. It gives you exclusive ‘digital bragging rights. . NFTs are not limited to pieces of digital artwork, though a bulk of the market comprises these; NFTs can also include concert tickets, domain names, in-game limited edition items, real estate and anything that is unique and requires proof of ownership. The prices of NFTs are not uniform and depend on supply-demand characteristics. A word of caution: an expensive NFT becomes worthless if no one wants to buy it! . . FAQs . Where can one buy NFTs? . NFTs can be bought online on open-source exchanges and NFT marketplaces. . Which blockchain is used in NFTs? . A bulk of contracts are executed on the Ethereum blockchain. .",
            "url": "https://shlok2002.github.io/blog/web3/2022/12/21/What-is-NFT.html",
            "relUrl": "/web3/2022/12/21/What-is-NFT.html",
            "date": " • Dec 21, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "ULIPs",
            "content": "Introduction . In today’s fast-paced world, financial planning is paramount. An individual is expected to know about investment and insurance. These financial products serve different purposes- Investing is related to wealth creation, whereas Insurance is financial protection. An individual must strike a balance between the two to have sound financial planning. Unit-linked insurance plans are a widely acclaimed investment cum insurance instrument globally. Unit-linked insurance plans, or ULIPs, as they are generally called, are integrated financial products that have features of both insurance and investment. . What is ULIP? . ULIP stands for Unit Linked Insurance Plan. This is an insurance product that offers investors exposure to capital markets. You can gain market-linked returns by investing in equity/ debt/ hybrid funds. With ULIPs, you can create wealth to achieve your life goals while the smiles of your loved ones stay protected. . How does ULIP Work? . Working on a Unit-Linked Insurance Plan is pretty simple. The insurer invests a part of the premium you have paid in shares or bonds, and the rest is invested in providing life cover. Once you pay the premium, several more investors invest in the same portfolio. The insurer further pools this money and, after deducting the expenses, invests in the fund chosen by you. It could be either equity, balanced or debt funds. The total sum of money is further divided into units. The insurance company allocates these units to each investor according to the amount invested. This unit value is called NAV or Net Asset Value. The units’ NAV either increase or decrease based on the market value. On maturity of the plan, the insurer pays the fund value to the investors depending upon the market value. In case of your untimely death, the insurer pays your beneficiary higher than the fund value or available fund value. ULIPs also allow you to switch between equities and debt and vice-versa if you wish to do so. If equity markets are not doing well, you can switch to debt to preserve your gains. On the other hand, you can move from debt to equity if you have a high-risk tolerance. This flexibility has made ULIP policies highly popular. . These instruments also have a five year lock-in period where the investor cannot withdraw their units. If you start prematurely, the death cover is ceased immediately, and you are paid the balance amount only after three years. . Types of ULIPs . ULIPs for long-term wealth creation: . Regular and Single Premium ULIP: In a standard premium ULIP, you need to pay dividends over some time. On the other hand, in a single premium ULIP, you pay the entire premium. You can choose the one as per your income and cash flow. Life staged based and Non-life stage based ULIP: Needs at different stages of life are different, isn’t it? Life stage based ULIPs invest your money accordingly. For example, when you are young and single, you may have a higher risk appetite, and, therefore, a higher allocation is towards equities. As you grow old, the equity allocation reduces. The strategy ensures asset allocation matches your age and financial requirements. However, this is not the case with a non-life stage-based plan. You choose the funds as per your risk appetite and can switch between them when desired. Guaranteed and Non-Guaranteed ULIP: Capital protection is the objective of guaranteed ULIP. It has limited equity exposure. On the other hand, a non-guaranteed ULIP offers you a range of funds as per your risk tolerance and financial goals. In these ULIPs, you can opt for a high equity . ULIPs to secure your child’s future (Goal Based): . As a parent, you want to give the best of everything to your child. It’s your responsibility to secure your child’s future and ensure their needs are met even in your absence. ULIPs for a child can help you in your efforts and ensures your child’s needs are well-taken care of even when you are no longer around. These ULIPs help you save and build a large corpus for your child’s higher education, and in case of an unfortunate event, the insurer pays a fixed lump sum that helps your family meet immediate requirements. Also, some plans offer the facility to partially withdraw to fund essential education milestones of your child’s life. . ULIPs for retirement: . Everyone dreams of a stress-free retirement. ULIPs for retirement help you save and invest in a disciplined manner to build a large retirement corpus that enables you to take care of your post-retirement needs with ease. While the purpose of the ULIP mentioned above plans may differ, they help you in disciplined savings and investments to achieve your set goal. . Why buy ULIPs? . Flexible: ULIPs offer investors the option of switching between funds, resulting in better choices for the investor. Investors can choose to invest in either debt or equity funds depending on their risk appetite and market conditions. Risk appetite: ULIPs offer investors to choose their investments based on their risk appetite. Low-risk appetite investors can choose to invest in debt funds, and those willing to take a higher risk can opt for equity funds. Low charges: ULIPs do not have high costs associated with them. IRDA has capped the annual fee on ULIPs at 2-2.25% p.a. for the initial ten years, with the charges on par with mutual funds. Long term investment: ULIPs are a long term investment option due to the increased lock-in period, which also reap more significant returns. Disciplined Investing: ULIP plans function with periodic regular investments in the form of premiums. This discipline of traditional investment takes you closer to the mission of wealth creation and achieving the financial goals at the right time. . Tax Benefits . Premium paid on ULIPs is eligible for a deduction under Section 80C up to a maximum of ₹ 1.5 lakhs during a year. Further, the amount you receive on maturity is tax-exempt under Section 10(10D). . . FAQs . When were ULIPs introduced in India? . ULIPs were first introduced in India by the Unit Trust of India (UTI) in 1971. Life Insurance Corporation of India (LIC), then, introduced more ULIP products in 1989. . Which organisations issue ULIP? . Generally, public and private sector insurance providers, which either operate solo or have partnered with foreign insurance companies, offer ULIP products to their customers. Offering ULIP products requires the approval of both the Reserve Bank of India (RBI) and the Insurance Regulatory and Development Authority of India (IRDAI). . Can I switch my investment fund choice after availing of ULIP? . Yes, Investors can freely switch between funds as per their wish and convenience. However, a certain switching charge is applicable and levied by insurance companies. .",
            "url": "https://shlok2002.github.io/blog/finance/investment%20101/2022/12/19/Ulips.html",
            "relUrl": "/finance/investment%20101/2022/12/19/Ulips.html",
            "date": " • Dec 19, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "Credit Cards",
            "content": "Introduction . Credit Cards work on the general principle of buy now and pay later. Apart from providing instant credit access, the cards also offer a host of other privileges, including cashback, reward points, discounts, and more. . When used wisely, credit cards can be a powerful financial asset. You can boost your credit score and other benefits by spending less daily. But if you are not financially disciplined, you tend to misuse your credit cards which leaves you in higher financial distress. Here are some common credit mistakes and tips on how to avoid them: . Making Late Payments . Paying your credit card debts late damages your credit score and may negatively impact your credit card issuer. A month’s late payment could reduce your credit card score by 100 points. Imagine you are late for three months or more. You also risk accumulating APR on your delinquent payments, increasing your debt profile. . . Set up autopay to ensure payments are always made on time. And if you don&#39;t prefer autopay, set calendar reminders and email notifications. Only Paying the Minimum Amount Due . Credit card issuers make it convenient to repay your balance by allowing minimum payments. However, paying more than the minimum amount is preferred when you can afford it. . Paying the minimum amount and revolving the credit to the next cycle can damage your finances like any missed or late payment. This is because interest is levied on the unpaid balance. When you pay only the minimum amount, the interest charges will be levied on the remaining balance. Paying the minimum can add more months — even years required to pay off your debt. . . Have a payment plan before you take on any bigger expenses, and always make consistent, on-time payments toward your balance. Not knowing your APR and applicable fees . When you apply and are approved for a credit card, you receive a long cardmember agreement that probably doesn’t top your must-read list. However, you must parse through the jargon and review important account terms to understand all the applicable fees. . Here are some key terms to look out for and what they mean: . Annual Fee: The yearly fee charged for holding a card. | Purchase APR: The annual percentage rate is the yearly interest rate purchases are charged when you carry a balance month-to-month Divide by 12 to get the monthly interest rate. | Late Payment Fee: The amount you are charged over and above the interest on the outstanding amount you owe for missing monthly payments. | Foreign Transaction Fee: Purchases made outside India often incur a fee, typically 2.5% - 3.5% per transaction. | Balance-Transfer Fee: When you transfer debt, you’ll often incur a 3% to 5% fee. | . Not Reviewing Your Account Statement . One common but easily avoidable mistake you can make on your credit card account is to overlook checking your account statement regularly. . Reviewing your credit card account periodically allows you to know the status of your account and prevent reporting or charging errors and potential frauds from taking advantage of your account. . If you cannot keep up with a weekly review, you should do a monthly account review to keep up with your bills and know the status of your account. . Having Too Many Credit Card Accounts . This might be a good idea in the short term because it gives you enough options to source lines of credit to cover your expenses. However, in the long run, what this means is that you will not be able to keep up with the accumulated debt on different credit card accounts. . These accounts will also charge APR, which means more debts. Also, when you apply for a new credit card, the card issuer may enquire about your credit cards, and too many inquiries may spook your existing lenders. . You can take advantage of Pre-qualification forms, which allow you to check if you qualify for a new credit card without damaging your credit score. . Taking Cash Advances . Taking out a cash advance is one of the costliest things you can do with your credit card. It may look like the most convenient way of getting some cash at your disposal, but it is also the most expensive one. . As soon as you withdraw the cash, the interest starts accruing on the amount withdrawn. Also, cash advances on credit cards attract an additional fee. Some banks charge a flat amount, while others charge a percentage of the amount withdrawn. . For example, the cash advance fee on HDFC Regalia is 2.5% of the transaction amount. . Maxing Out your Card . Using the majority, or all, of your available credit, is never a good idea. The amount of credit you use plays into your utilisation rate. The higher the utilisation rate, the lower your credit score. . If you frequently charge close to your monthly limit and have no problem paying off your bill, you can call the credit card company and ask for a credit increase. . . FAQs . What is APR? . The annual percentage rate (APR) refers to the yearly interest you pay on your borrowed amount to your credit card provider. . Who Issues Credit Scores in India? . The Reserve Bank of India has provided authorization to companies that have registered under The Credit Information Companies (Regulation) Act, 2005 to provide credit scores or ratings based on the past performances that have been reported by numerous member credit institutions and banks. CIBIL or Credit Information Bureau India Limited is India’s leading credit information bureau. .",
            "url": "https://shlok2002.github.io/blog/finance/2022/12/16/Credit-Card.html",
            "relUrl": "/finance/2022/12/16/Credit-Card.html",
            "date": " • Dec 16, 2022"
        }
        
    
  
    
        ,"post9": {
            "title": "Market Basket Analysis",
            "content": "Dataset . The dataset is publicly available from the Kaggle website. It contains the Transactions data from a bakery from 30/10/2016 to 09/04/2017. The data belongs to a bakery called &quot;The Bread Basket&quot; that serves coffee, bread, muffin, cookies and so on. It is located in the historic center of Edinburgh. . Understanding MBA . Market basket analysis (MBA), also known as association-rule mining, is a useful method of discovering customer purchasing patterns by extracting associations or co-occurrences from stores&#39; transactional databases (Chen et al., 2005). It is a modelling technique based upon the theory that if you buy a certain group of items, you are more (or less) likely to buy another group of items. For example, if you are in a supermarket and you buy a loaf of Bread, you are more likely to buy a packet of Butter at the same time than somebody who didn&#39;t buy the Bread. Another example, if you are buying a XiaoMi Power Bank in an online store, you are more likely to also buy a carrying case to go with the power bank. Amazon knows this well from the transaction data of its millions of customers and thus recommends a case to you as seen below: . . The set of items a customer buys is known as an itemset, and MBA tries to identify relationships from the purchases of itemset. The output of MBA consists of a series of product association rules. From the transaction data extracted from the shopping carts of online retailers or the point of sales system of retail stores, we can use MBA to extract interesting association rules between products. For example, if customers buy product A they also tend to buy product B. . Typically we can extract the relationship between products in the form of a rule, an example of association rule: . IF {bread} THEN {butter}. . In this example, if customers buy Bread they also tend to buy Butter. Some people often link products with high association to &quot;complementary goods&quot;. In Economics 101, complementary good or service is consumed or used in conjunction with another good or service. Usually, the complementary good has little to no value when consumed alone, but when combined with another good or service, it adds to the overall value of the offering. For example a car and petrol. It would be of little value to buy petrol without owning a car. Complementary goods often have a negative cross-price elasticity of demand coefficient (Farnham, 2014). However, it is worth pointing out that, while complementary goods tend to have high association, not all products with high association rules are complementary goods. In MBA, we are more interested in product-pairs with high association rules i.e. products that are frequently purchased together. For example, in a retail store, MBA findings may show that Barbie dolls and candy are frequently purchased together, even though they are not technically complementary goods. In short, complementary goods are fairly obvious and common sense, but MBA seeks to uncover product associations that may not be so obvious and straighforward. In doing so, it is attempting to convert the abstract consumer tastes and preferences into association rules that are more insightful and actionable, from business perspective. . . Applications . There are many real-life applications of MBA: . Recommendation engine – showing related products as &quot;Customers Who Bought This Item Also Bought&quot; or “Frequently bought together” (as shown in the Amazon example above). It can also be applied to recommend videos and news article by analyzing the videos or news articles that are often watched or read together in a user session. | Cross-sell / bundle products – selling associated products as a &quot;bundle&quot; instead of individual items. For example, transaction data may show that customers often buy a new phone with screen protector together. Phone retailers can then package new phone with high-margin screen protector together and sell them as a bundle, thereby increasing their sales. | Arrangement of items in retail stores – associated items can be placed closer to each other, thereby invoking &quot;impulse buying&quot;. For example it may be uncovered that customers who buy Barbie dolls also buy candy at the same time. Thus retailers can place high-margin candy near Barbie doll display, thereby tempting customers to buy them together. | Detecting fraud – identifying related actions whenever a fraudulent transaction is performed. For example, in a fraudulent insurance claim for stolen vehicle, it may be analyzed (from historical data) that claimant frequently report the incident a few days late (action 1) and often refuse to cooperate with insurer on investigation (action 2). Insurers can identify these red flags once certain behaviours or actions are displayed by the claimants. | . . Case Study . For simplicity we are analyzing only 2 items – Bread and Butter. We want to know if there is any evidence that suggests that buying Bread leads to buying Butter. . Problem Statament: Is the purchase of Bread leads to the purchase of Butter? Hypothesis: There is significant evidence to show that buying Bread leads to buying Butter. . Bread =&gt; Butter . Antecedent =&gt; Consequent . Let&#39;s take the example of a supermarket which generates 1,000 transactions monthly, of which Bread was purchased in 150 transactions, Butter in 130 transactions, and both together in 50 transactions. . In set theory it can be represented as Bread only – 100, Butter only – 80, Bread and Butter – 50, as shown in the Venn diagram below: . . Analysis and Findings . We can use MBA to extract the association rule between Bread and Butter. There are three metrics or criteria to evaluate the strength or quality of an association rule, which are support, confidence and lift. . 1. Support . Support measures the percentage of transactions containing a particular combination of items relative to the total number of transactions. In our example, this is the percentage of transactions where both Bread and Butter are bought together. We need to calculate this to know if this combination of items is significant or negligible? Generally, we want a high percentage i.e. high support in order to make sure it is a useful relationship. Typically, we will set a threshold, for example we will only look at a combination if more than 1% of transactions have this combination. . Support (antecedent (Bread) and consequent (Butter)) = Number of transactions having both items / Total transactions . . Result: The support value of 5% means 5% of all transactions have this combination of Bread and Butter bought together. Since the value is above the threshold of 1%, it shows there is indeed support for this association and thus satisfy the first criteria. . . 2. Confidence . Confidence measures the probability of finding a particular combination of items whenever antecedent is bought. In probability terms, confidence is the conditional probability of the consequent given the antecedent and is represented as P (consequent / antecedent). In our example, it is the probability of both Bread and Butter being bought together whenever Bread is bought. Typically, we may set a threshold, say we want this combination to occur at least 25% of times when Bread is bought. . Confidence (antecedent i.e. Bread and consequent i.e. Butter) = P (Consequent (Butter) is bought GIVEN antecedent (Bread) is bought) . . Result: The confidence value of 33.3% is above the threshold of 25%, indicating we can be confident that Butter will be bought whenever Bread is bought, and thus satisfy the second criteria. . . 3. Lift . Lift is a metric to determine how much the purchase of antecedent influences the purchase of consequent. In our example, we want to know whether the purchase of Butter is independent of the purchase of Bread (or) is the purchase of Butter happening due to the purchase of Bread? In probability terms, we want to know which is higher, P (Butter) or P (Butter / Bread)? If the purchase of Butter is influenced by the purchase of Bread, then P (Butter / Bread) will be higher than P (Butter), or in other words, the ratio of P (Butter / Bread) over P (Butter) will be higher than 1. . . Result: The lift value of 2.56 is greater than 1, it shows that the purchase of Butter is indeed influenced by the purchase of Bread rather than Butter&#39;s purchase being independent of Bread. The lift value of 2.56 also means that Bread&#39;s purchase lifts the Butter&#39;s purchase by 2.56 times. . . Conclusion . Based on the findings above, we can justify our initial hypothesis as we . a) Have the support of 5% transactions for Bread and Butter in the same basket b) Have 33.3% confidence that Butter sales happen whenever Bread is purchased. c) Knows the lift in Butter&#39;s sales is 2.56 times more, whenever Bread is purchased than when Butter is purchased alone. . Therefore, we can conclude that there is indeed evidence to suggest that the purchase of Bread leads to the purchase of Butter. This is a valuable insight to guide management&#39;s decision-making. For example, managers of retail stores could start placing bread and butter close to each other, knowing that customers are highly likely to &quot;impulsively&quot; purchase them together, thereby increasing the store&#39;s revenue. . Implementation in Python . Importing libraries . %matplotlib inline !pip install mlxtend import numpy as np import pandas as pd import matplotlib.pyplot as plt from mlxtend.frequent_patterns import apriori from mlxtend.frequent_patterns import association_rules . Requirement already satisfied: mlxtend in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (0.21.0) Requirement already satisfied: scikit-learn&gt;=1.0.2 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.0.2) Requirement already satisfied: matplotlib&gt;=3.0.0 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (3.5.2) Requirement already satisfied: pandas&gt;=0.24.2 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.4.4) Requirement already satisfied: scipy&gt;=1.2.1 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.9.1) Requirement already satisfied: numpy&gt;=1.16.2 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.21.5) Requirement already satisfied: joblib&gt;=0.13.2 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (1.1.0) Requirement already satisfied: setuptools in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from mlxtend) (63.4.1) Requirement already satisfied: fonttools&gt;=4.22.0 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from matplotlib&gt;=3.0.0-&gt;mlxtend) (4.25.0) Requirement already satisfied: pillow&gt;=6.2.0 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from matplotlib&gt;=3.0.0-&gt;mlxtend) (9.2.0) Requirement already satisfied: cycler&gt;=0.10 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from matplotlib&gt;=3.0.0-&gt;mlxtend) (0.11.0) Requirement already satisfied: kiwisolver&gt;=1.0.1 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from matplotlib&gt;=3.0.0-&gt;mlxtend) (1.4.2) Requirement already satisfied: packaging&gt;=20.0 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from matplotlib&gt;=3.0.0-&gt;mlxtend) (21.3) Requirement already satisfied: pyparsing&gt;=2.2.1 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from matplotlib&gt;=3.0.0-&gt;mlxtend) (3.0.9) Requirement already satisfied: python-dateutil&gt;=2.7 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from matplotlib&gt;=3.0.0-&gt;mlxtend) (2.8.2) Requirement already satisfied: pytz&gt;=2020.1 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from pandas&gt;=0.24.2-&gt;mlxtend) (2022.1) Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn&gt;=1.0.2-&gt;mlxtend) (2.2.0) Requirement already satisfied: six&gt;=1.5 in /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib&gt;=3.0.0-&gt;mlxtend) (1.16.0) . . Load Data . bread = pd.read_csv(&quot;BreadBasket_DMS.csv&quot;) bread.head(10) . Date Time Transaction Item . 0 2016-10-30 | 09:58:11 | 1 | Bread | . 1 2016-10-30 | 10:05:34 | 2 | Scandinavian | . 2 2016-10-30 | 10:05:34 | 2 | Scandinavian | . 3 2016-10-30 | 10:07:57 | 3 | Hot chocolate | . 4 2016-10-30 | 10:07:57 | 3 | Jam | . 5 2016-10-30 | 10:07:57 | 3 | Cookies | . 6 2016-10-30 | 10:08:41 | 4 | Muffin | . 7 2016-10-30 | 10:13:03 | 5 | Coffee | . 8 2016-10-30 | 10:13:03 | 5 | Pastry | . 9 2016-10-30 | 10:13:03 | 5 | Bread | . bread.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 21293 entries, 0 to 21292 Data columns (total 4 columns): # Column Non-Null Count Dtype -- -- 0 Date 21293 non-null object 1 Time 21293 non-null object 2 Transaction 21293 non-null int64 3 Item 21293 non-null object dtypes: int64(1), object(3) memory usage: 665.5+ KB . . Note: There are 21,293 rows and 4 columns in the dataframe. Date and Time columns are encoded in &#8217;object&#8217; instead of Datetime, but fortunately there is a Transaction column which helps to identify each transaction. Item column contains the individual items in that transaction. For example, Transaction No. 3 contains items of &quot;Hot chocolate&quot;, &quot;Jam&quot;, and &quot;Cookies&quot; which are all transacted in the same time i.e 10.07.57 on 2016-10-30. . Checking for missing values . bread.isnull().sum() . Date 0 Time 0 Transaction 0 Item 0 dtype: int64 . missing_value = [&quot;NaN&quot;, &quot;NONE&quot;, &quot;None&quot;, &quot;Nan&quot;, &quot;nan&quot;, &quot;nil&quot;, &quot;none&quot;] print(&quot;There are {0} missing values in the dataframe.&quot;.format(len(bread[bread.Item.isin(missing_value)]))) bread[bread.Item.isin(missing_value)].head(10) . There are 786 missing values in the dataframe. . Date Time Transaction Item . 26 2016-10-30 | 10:27:21 | 11 | NONE | . 38 2016-10-30 | 10:34:36 | 15 | NONE | . 39 2016-10-30 | 10:34:36 | 15 | NONE | . 66 2016-10-30 | 11:05:30 | 29 | NONE | . 80 2016-10-30 | 11:37:10 | 37 | NONE | . 85 2016-10-30 | 11:55:51 | 40 | NONE | . 126 2016-10-30 | 13:02:04 | 59 | NONE | . 140 2016-10-30 | 13:37:25 | 65 | NONE | . 149 2016-10-30 | 13:46:48 | 67 | NONE | . 167 2016-10-30 | 14:32:26 | 75 | NONE | . . Note: While there is no empty cell in the dataframe, a check using the popular missing value shows that there are 786 rows with &quot;NONE&quot; in the column Item. Since the items are not recorded, we will have to remove these rows. . bread = bread.drop(bread[bread.Item == &quot;NONE&quot;].index) print(&quot;Number of rows:{0}&quot;.format(len(bread))) bread.head(10) . Number of rows:20507 . Date Time Transaction Item . 0 2016-10-30 | 09:58:11 | 1 | Bread | . 1 2016-10-30 | 10:05:34 | 2 | Scandinavian | . 2 2016-10-30 | 10:05:34 | 2 | Scandinavian | . 3 2016-10-30 | 10:07:57 | 3 | Hot chocolate | . 4 2016-10-30 | 10:07:57 | 3 | Jam | . 5 2016-10-30 | 10:07:57 | 3 | Cookies | . 6 2016-10-30 | 10:08:41 | 4 | Muffin | . 7 2016-10-30 | 10:13:03 | 5 | Coffee | . 8 2016-10-30 | 10:13:03 | 5 | Pastry | . 9 2016-10-30 | 10:13:03 | 5 | Bread | . . Note: After removing the missing values, the number of rows left is 20,507 (original 21,293 minus 786 missing) . Convert to DatetimeIndex . bread[&#39;Datetime&#39;] = pd.to_datetime(bread[&#39;Date&#39;]+&#39; &#39;+bread[&#39;Time&#39;]) bread = bread[[&quot;Datetime&quot;, &quot;Transaction&quot;, &quot;Item&quot;]]. set_index(&quot;Datetime&quot;) bread.head(10) . Transaction Item . Datetime . 2016-10-30 09:58:11 1 | Bread | . 2016-10-30 10:05:34 2 | Scandinavian | . 2016-10-30 10:05:34 2 | Scandinavian | . 2016-10-30 10:07:57 3 | Hot chocolate | . 2016-10-30 10:07:57 3 | Jam | . 2016-10-30 10:07:57 3 | Cookies | . 2016-10-30 10:08:41 4 | Muffin | . 2016-10-30 10:13:03 5 | Coffee | . 2016-10-30 10:13:03 5 | Pastry | . 2016-10-30 10:13:03 5 | Bread | . Quick stats . total_items = len(bread) total_days = len(np.unique(bread.index.date)) total_months = len(np.unique(bread.index.month)) average_items = total_items / total_days unique_items = bread.Item.unique().size print(&quot;There are {} unique items sold by the Bakery&quot;.format(unique_items)) print(&quot;Total {} items sold in {} days throughout {} months&quot;.format(total_items, total_days, total_months)) print(&quot;With an average of {} items sold daily&quot;.format(average_items)) . There are 94 unique items sold by the Bakery Total 20507 items sold in 159 days throughout 7 months With an average of 128.9748427672956 items sold daily . . Note: We have combined the Date and Time columns into a single Datetime column, convert it into datetime64 type, and then set it as DatetimeIndex. This will make it easier to plot the time series charts later on. Also, a quick look at the data shows that the Bakery sold an average of 129 items daily. . Visualisation . bread.Item.value_counts(normalize=True)[:10] . Coffee 0.266787 Bread 0.162140 Tea 0.069976 Cake 0.049983 Pastry 0.041742 Sandwich 0.037597 Medialuna 0.030039 Hot chocolate 0.028771 Cookies 0.026332 Brownie 0.018481 Name: Item, dtype: float64 . bread.Item.value_counts(normalize=True)[:10].plot(kind=&quot;bar&quot;, title=&quot;Percentage of Sales by Item&quot;).set(xlabel=&quot;Item&quot;,ylabel=&quot;Percentage&quot;) . [Text(0.5, 0, &#39;Item&#39;), Text(0, 0.5, &#39;Percentage&#39;)] . bread.Item.value_counts()[:10].plot(kind=&quot;bar&quot;, title=&quot;Total Number of Sales by Item&quot;).set(xlabel=&quot;Item&quot;, ylabel=&quot;Total Number&quot;) . [Text(0.5, 0, &#39;Item&#39;), Text(0, 0.5, &#39;Total Number&#39;)] . . Note: From the bar charts above, it is clear that Coffee (26.7%) is the best-selling item in the bakery, follow by Bread (16.2%) and Tea (7.0%). . bread[&quot;Item&quot;].resample(&quot;D&quot;).count().plot(figsize=(12,5), grid=True, title=&quot;Total Number of Items Sold by Date&quot;).set(xlabel=&quot;Date&quot;,ylabel=&quot;Total Number of Items Sold&quot;) . [Text(0.5, 0, &#39;Date&#39;), Text(0, 0.5, &#39;Total Number of Items Sold&#39;)] . . Note: Total Number of Items Sold by Date fluctuates a lot thoughout the 159 days of data . bread[&quot;Item&quot;].resample(&quot;M&quot;).count() . Datetime 2016-10-31 369 2016-11-30 4436 2016-12-31 3339 2017-01-31 3356 2017-02-28 3906 2017-03-31 3944 2017-04-30 1157 Freq: M, Name: Item, dtype: int64 . bread[&quot;Item&quot;].resample(&quot;M&quot;).count().plot(figsize=(12,5), grid=True, title=&quot;Total Number by Items Sold by Month&quot;).set(xlabel=&quot;Date&quot;,ylabel=&quot;Total Number of Items Sold&quot;) . [Text(0.5, 0, &#39;Date&#39;), Text(0, 0.5, &#39;Total Number of Items Sold&#39;)] . . Note: Given that the beginning month (October 2016) and ending month (April 2017) are not full month, the total number of items sold by month for the five full month between November 2016 to March 2017 does not fluctuate too much . # For Datetimeindex, the day of the week with Monday=0, Sunday=6, thereby +1 to become Monday=1, Sunday=7 bread[&quot;Hour&quot;] = bread.index.hour bread[&quot;Weekday&quot;] = bread.index.weekday + 1 bread.head(10) . Transaction Item Hour Weekday . Datetime . 2016-10-30 09:58:11 1 | Bread | 9 | 7 | . 2016-10-30 10:05:34 2 | Scandinavian | 10 | 7 | . 2016-10-30 10:05:34 2 | Scandinavian | 10 | 7 | . 2016-10-30 10:07:57 3 | Hot chocolate | 10 | 7 | . 2016-10-30 10:07:57 3 | Jam | 10 | 7 | . 2016-10-30 10:07:57 3 | Cookies | 10 | 7 | . 2016-10-30 10:08:41 4 | Muffin | 10 | 7 | . 2016-10-30 10:13:03 5 | Coffee | 10 | 7 | . 2016-10-30 10:13:03 5 | Pastry | 10 | 7 | . 2016-10-30 10:13:03 5 | Bread | 10 | 7 | . bread_groupby_hour = bread.groupby(&quot;Hour&quot;).agg({&quot;Item&quot;: lambda item: item.count()/total_days}) bread_groupby_hour . Item . Hour . 1 0.006289 | . 7 0.150943 | . 8 4.056604 | . 9 12.364780 | . 10 16.767296 | . 11 19.509434 | . 12 17.949686 | . 13 16.459119 | . 14 16.603774 | . 15 13.301887 | . 16 8.446541 | . 17 2.314465 | . 18 0.515723 | . 19 0.301887 | . 20 0.138365 | . 21 0.018868 | . 22 0.050314 | . 23 0.018868 | . bread_groupby_hour.plot(y=&quot;Item&quot;, figsize=(12,5), title=&quot;Average Number by Items Sold by Hour of the Day&quot;).set(xlabel=&quot;Hour of the Day (24 hour time)&quot;, ylabel=&quot;Average Number of Items Sold&quot;) . [Text(0.5, 0, &#39;Hour of the Day (24 hour time)&#39;), Text(0, 0.5, &#39;Average Number of Items Sold&#39;)] . . Note: Sales starts to pick up from 8am, till the busiest hour of the day at 11am, then slowly drops till the late afternoon. It can be observed that most of the sales transactions took place during the lunch hours of the day . bread_groupby_weekday = bread.groupby(&quot;Weekday&quot;).agg({&quot;Item&quot;: lambda item: item.count()}) bread_groupby_weekday . Item . Weekday . 1 2324 | . 2 2392 | . 3 2321 | . 4 2646 | . 5 3124 | . 6 4605 | . 7 3095 | . # in order to calculate the average items per weekday import datetime daterange = pd.date_range(datetime.date(2016, 10, 30), datetime.date(2017, 4, 9)) monday = 0 tuesday = 0 wednesday = 0 thursday = 0 friday = 0 saturday = 0 sunday = 0 for day in np.unique(bread.index.date): if day.isoweekday() == 1: monday += 1 elif day.isoweekday() == 2: tuesday += 1 elif day.isoweekday() == 3: wednesday += 1 elif day.isoweekday() == 4: thursday += 1 elif day.isoweekday() == 5: friday += 1 elif day.isoweekday() == 6: saturday += 1 elif day.isoweekday() == 7: sunday += 1 all_weekdays = monday + tuesday + wednesday + thursday + friday + saturday + sunday print(&quot;monday = {0}, tuesday = {1}, wednesday = {2}, thursday = {3}, friday = {4}, saturday = {5}, sunday = {6}, total = {7}&quot;.format(monday, tuesday, wednesday, thursday, friday, saturday, sunday, all_weekdays)) . monday = 21, tuesday = 23, wednesday = 23, thursday = 23, friday = 23, saturday = 23, sunday = 23, total = 159 . conditions = [ (bread_groupby_weekday.index == 1), (bread_groupby_weekday.index == 2), (bread_groupby_weekday.index == 3), (bread_groupby_weekday.index == 4), (bread_groupby_weekday.index == 5), (bread_groupby_weekday.index == 6), (bread_groupby_weekday.index == 7)] choices = [bread_groupby_weekday.Item/21, bread_groupby_weekday.Item/23, bread_groupby_weekday.Item/23, bread_groupby_weekday.Item/23, bread_groupby_weekday.Item/23, bread_groupby_weekday.Item/23, bread_groupby_weekday.Item/23] bread_groupby_weekday[&quot;Average&quot;] = np.select(conditions, choices, default=0) bread_groupby_weekday . Item Average . Weekday . 1 2324 | 110.666667 | . 2 2392 | 104.000000 | . 3 2321 | 100.913043 | . 4 2646 | 115.043478 | . 5 3124 | 135.826087 | . 6 4605 | 200.217391 | . 7 3095 | 134.565217 | . bread_groupby_weekday.plot(y=&quot;Average&quot;, figsize=(12,5), title=&quot;Average Number by Items Sold by Day of the Week&quot;).set(xlabel=&quot;Day of the Week (1=Monday, 7=Sunday)&quot;, ylabel=&quot;Average Number of Items Sold&quot;) . [Text(0.5, 0, &#39;Day of the Week (1=Monday, 7=Sunday)&#39;), Text(0, 0.5, &#39;Average Number of Items Sold&#39;)] . . Note: Saturday is the busiest day of the week with the highest sales (~200 items) while Wednesday is the quietest day with the lowest sales (~101 items). This is an interesting insight, the owner of the Bakery should launch some promotion activities to boost up sales in the middle of the week when sales are slowest. . The Apriori function in the MLxtend library expects data in a one-hot encoded pandas DataFrame. This means that all the data for a transaction must be included in one row and the items must be one-hot encoded. Example below: . Coffee Cake Bread Cookie Muffin Tea Milk Juice Sandwich . 0 | 0 | 1 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | . 1 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | . 2 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | . 3 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | . 4 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . Therefore, we&#39;ll need to group the bread dataframe by Transaction and Item and display the count of items. Then we need to consolidate the items into one transaction per row with each item one-hot encoded. . df = bread.groupby([&quot;Transaction&quot;,&quot;Item&quot;]).size().reset_index(name=&quot;Count&quot;) df.head() . Transaction Item Count . 0 1 | Bread | 1 | . 1 2 | Scandinavian | 2 | . 2 3 | Cookies | 1 | . 3 3 | Hot chocolate | 1 | . 4 3 | Jam | 1 | . basket = (df.groupby([&#39;Transaction&#39;, &#39;Item&#39;])[&#39;Count&#39;] .sum().unstack().reset_index().fillna(0) .set_index(&#39;Transaction&#39;)) basket.head() . Item Adjustment Afternoon with the baker Alfajores Argentina Night Art Tray Bacon Baguette Bakewell Bare Popcorn Basket ... The BART The Nomad Tiffin Toast Truffles Tshirt Valentine&#39;s card Vegan Feast Vegan mincepie Victorian Sponge . Transaction . 1 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 2 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 3 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 4 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 5 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 5 rows × 94 columns . basket[basket.Coffee == 4].iloc[:,14:28] . Item Brownie Cake Caramel bites Cherry me Dried fruit Chicken Stew Chicken sand Chimichurri Oil Chocolates Christmas common Coffee Coffee granules Coke Cookies Crepes . Transaction . 6560 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 4.0 | 0.0 | 0.0 | 1.0 | 0.0 | . 6850 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 4.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 6887 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 4.0 | 0.0 | 0.0 | 0.0 | 0.0 | . . Important: At this stage, the one-hot encoded table shows the count of items purchased as result. If you observe the portion of the table above, in Transaction 6887, the cell value for Coffee is &quot;4.0&quot; because there were 4 coffee purchased in this transaction. However, this is not important for us and we need to convert this value into 1. . def encode_units(x): if x &lt;= 0: return 0 if x &gt;= 1: return 1 . basket_sets = basket.applymap(encode_units) basket_sets.head() . Item Adjustment Afternoon with the baker Alfajores Argentina Night Art Tray Bacon Baguette Bakewell Bare Popcorn Basket ... The BART The Nomad Tiffin Toast Truffles Tshirt Valentine&#39;s card Vegan Feast Vegan mincepie Victorian Sponge . Transaction . 1 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 3 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 rows × 94 columns . basket_sets[basket_sets.Coffee == 1].iloc[3142:3145,14:28] . Item Brownie Cake Caramel bites Cherry me Dried fruit Chicken Stew Chicken sand Chimichurri Oil Chocolates Christmas common Coffee Coffee granules Coke Cookies Crepes . Transaction . 6884 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | . 6885 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | . 6887 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | . . Note: After applying the encoding function, for the same Transaction 6887, the cell value for Coffee has become &quot;1&quot; which is what we need for the Apriori function. . Generate Frequent Itemsets . Now, we are ready to generate the frequent item sets. We will set the minimum-support threshold at 1% . frequent_itemsets = apriori(basket_sets, min_support=0.01, use_colnames=True) . /Users/shlokkamat/opt/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:111: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type warnings.warn( . . Generate Association Rules . The final step is to generate the rules with their corresponding support, confidence and lift. We will set the minimum threshold for lift at 1 and then sort the result by descending confidence value. . rules = association_rules(frequent_itemsets, metric=&quot;lift&quot;, min_threshold=1) rules.sort_values(&quot;confidence&quot;, ascending = False, inplace = True) rules.head(10) . antecedents consequents antecedent support consequent support support confidence lift leverage conviction . 31 (Toast) | (Coffee) | 0.033597 | 0.478394 | 0.023666 | 0.704403 | 1.472431 | 0.007593 | 1.764582 | . 28 (Spanish Brunch) | (Coffee) | 0.018172 | 0.478394 | 0.010882 | 0.598837 | 1.251766 | 0.002189 | 1.300235 | . 19 (Medialuna) | (Coffee) | 0.061807 | 0.478394 | 0.035182 | 0.569231 | 1.189878 | 0.005614 | 1.210871 | . 23 (Pastry) | (Coffee) | 0.086107 | 0.478394 | 0.047544 | 0.552147 | 1.154168 | 0.006351 | 1.164682 | . 1 (Alfajores) | (Coffee) | 0.036344 | 0.478394 | 0.019651 | 0.540698 | 1.130235 | 0.002264 | 1.135648 | . 17 (Juice) | (Coffee) | 0.038563 | 0.478394 | 0.020602 | 0.534247 | 1.116750 | 0.002154 | 1.119919 | . 25 (Sandwich) | (Coffee) | 0.071844 | 0.478394 | 0.038246 | 0.532353 | 1.112792 | 0.003877 | 1.115384 | . 7 (Cake) | (Coffee) | 0.103856 | 0.478394 | 0.054728 | 0.526958 | 1.101515 | 0.005044 | 1.102664 | . 27 (Scone) | (Coffee) | 0.034548 | 0.478394 | 0.018067 | 0.522936 | 1.093107 | 0.001539 | 1.093366 | . 13 (Cookies) | (Coffee) | 0.054411 | 0.478394 | 0.028209 | 0.518447 | 1.083723 | 0.002179 | 1.083174 | . Interpretation and Implications . The output above shows the Top 10 itemsets sorted by confidence value and all itemsets have support value over 1% and lift value over 1. The first itemset shows the association rule &quot;if Toast then Coffee&quot; with support value at 0.023666 means nearly 2.4% of all transactions have this combination of Toast and Coffee bought together. We also have 70% confidence that Coffee sales happen whenever a Toast is purchased. The lift value of 1.47 (greater than 1) shows that the purchase of Coffee is indeed influenced by the purchase of Toast rather than Coffee&#39;s purchase being independent of Toast. The lift value of 1.47 means that Toast&#39;s purchase lifts the Coffee&#39;s purchase by 1.47 times. . Therefore, we can conclude that there is indeed evidence to suggest that the purchase of Toast leads to the purchase of Coffee. The owner of the bakery &quot;The Bread Basket&quot; should consider bundling Toast and Cofee together as a Breakfast Set or Lunch Set, the staff in the store should also be trained to cross-sell Coffee to customers who purchase Toast, knowing that they are more likely to purchase them together, thereby increasing the store&#39;s revenue. . References . Chen, Y.L., Tang, K., Shen, R. J. &amp; Hu, Y. H. (2005). Market basket analysis in a multiple store environment. Decision Support Systems, 40(2), 339-354. | Farnham, P. G. (2014). Economics for Managers (3rd ed.). Essex, England: Pearson Education Limited. | Kaur, M. &amp; Kang, S. (2016). Market Basket Analysis: Identify the Changing Trends of Market Data Using Association Rule Mining. Procedia Computer Science, 85, 78-85. | Li, S. (2017, September 25), A Gentle Introduction on Market Basket Analysis — Association Rules. Towards Data Science. Retrieved from https://towardsdatascience.com/a-gentle-introduction-on-market-basket-analysis-association-rules-fa4b986a40ce | Moffitt, C. (2017, July 3). Introduction to Market Basket Analysis in Python. Practical Business Python. Retrieved from http://pbpython.com/market-basket-analysis.html | Rajaram, M. (2018, October 11). Market Basket Explained. Indium Software. Retrieved from https://indiumsoftware.com/blog/market-basket-explained/ | Wong, G. (2018, October 12). MBA For Breakfast or also known as the Market Basket Analysis. Towards Data Science. Retrieved from https://towardsdatascience.com/mba-for-breakfast-4c18164ef82b |",
            "url": "https://shlok2002.github.io/blog/machine%20learning/analytics/2022/12/15/Market-Basket-Analysis.html",
            "relUrl": "/machine%20learning/analytics/2022/12/15/Market-Basket-Analysis.html",
            "date": " • Dec 15, 2022"
        }
        
    
  
    
        ,"post10": {
            "title": "Factor Investing",
            "content": "Introduction . We have heard multiple strategies to make money in the stock markets. One lesser-known investing strategy is factor investing. Factor investing is an investment approach that targets specific return drivers across asset classes. . What are the factors? . Factors are the foundation of investing. They are broad, persistent drivers of returns across asset classes. Factors work to better capture the potential for excess returns and reduced risks. There are broadly two types of factors that have driven returns - macroeconomic factors, which capture broad risks across asset classes, and style factors, which help explain returns and risk within asset classes. . What is Factor Investing? . Factor investing is designed to enhance diversification, generate above-market returns and manage risk. Portfolio diversification has long been a popular safety tactic, but diversification gains are lost if the chosen securities move in lockstep with the broader market. For example, an investor may select a mixture of stocks and bonds that all decline in value when certain market conditions arise. The good news is factor investing can offset potential risks by targeting broad, persistent, and long-recognized drivers of returns. . Macroeconomic Factors . Economic Growth: The Gross Domestic Product (GDP) of a country, how well is the country poised to grow, what are the drivers of this growth, etc.? | Real rates: The risks and opportunities presented by the changes in interest rates, their effect on bond yields, and how one can maximise returns and reduce risks by dynamic allocation in interest rate-dependent asset classes. | Credit: How a business manages its credit, default probability, and ability to repay the debt on time play an important role while choosing asset classes. | Emerging Markets: Government stability and resource dependency are essential in making investment decisions. | . Style factors . Value: It aims to capture excess returns from stocks with low prices relative to their fundamental value. This is commonly tracked by price to book, price to earnings, dividends, and free cash flow. | Size: Historically, portfolios consisting of small-cap stocks exhibit greater returns than portfolios with just large-cap stocks. Investors can capture size by looking at the market capitalization of a stock. | Momentum: Stocks that have outperformed in the past tend to exhibit strong returns going forward. A momentum strategy is grounded in relative returns from three months to one year. | Quality: It is defined by low debt, stable earnings, consistent asset growth, and strong corporate governance. Investors can identify quality stocks using standard financial metrics like a return to equity, debt to equity, and earnings variability. | Volatility: Empirical research suggests that stocks with low volatility earn greater risk-adjusted returns than highly volatile assets. Measuring standard deviation from a one- to three-year time frame is a standard method of capturing beta. | . Pros of factor Investing . Tried and tested: The biggest pro of factor investing is that it has worked in the long term. Focusing on one factor at a time can help simplify the analysis process for investors who might otherwise get overwhelmed by thousands of fundamental and technical analysis metrics for each stock. | Diversified approach: Finally, different factors can have a relatively low correlation, allowing investors to potentially reduce their portfolios’ overall risk and volatility by diversifying based on several factors. | . Cons of factor Investing . Longer-term approach: Factor investing is a long-term strategy; investors shouldn’t necessarily expect outperformance over months or even years. In fact, it can take several years to even test a potential factor as a viable investment strategy. Just because a factor has worked in the past doesn’t mean it will continue to work in the future. | Potential bias: Factor investors can also be prone to selection bias. If you back-test enough factors for outperformance, you will eventually find factors that have generated positive historical results simply by chance. | Unknown risks: Finally, correlations among different factors change over time, potentially creating more risk in a multifactor portfolio than investors realize. | . Bottom-Line . It’s essential to remember that the factors are expected to outperform the broad market primarily over the long term. Each of these factors has extended periods in its history where it underperforms the general market or has significant drawdowns. One way managers try to get around this is by diversifying among the factors and using macroeconomic factors to construct their portfolios. This approach is called smart beta investing. . . FAQs . What is smart beta investing? . Smart beta investment portfolios are long-only rules-based investment strategies that aim to outperform a capitalization-weighted benchmark. . Is factor investing active or passive? . It is an investment strategy that combines active with passive styles of investing in order to capture excess returns at reduced risk. . How long should one be invested in factor investing portfolios? . An ideal timeline is long-term. This could be anytime from 5 years to a decade. .",
            "url": "https://shlok2002.github.io/blog/finance/investment%20101/2022/12/15/Factor-Investing.html",
            "relUrl": "/finance/investment%20101/2022/12/15/Factor-Investing.html",
            "date": " • Dec 15, 2022"
        }
        
    
  
    
        ,"post11": {
            "title": "Python Editor",
            "content": "Background . Time spent thinking about doing something takes away the time you have to actually do it. . Having read the above words of advice on my Instagram feed, I decided to research interesting things to do when you have a lot of time to spend. I somewhat had an idea that I wanted to do something related to computers, maybe read about some new technology or try learning a new programming language. While browsing the internet, I came across an interesting YouTube video title “Python Project Create Real Software”. . I have been using python for scientific computing on Google Collaboratory for my university courses but have never had the opportunity to use this powerful language to create something. So keeping in mind the above quote, I jumped right into ‘creating’ this project. . I am writing this blog as an experience of mine and not a review per se. I appreciate the content creator for his efforts and give him full credit for the coding aspect of the project. . Pre-requisites: . Basic Knowledge of Python: Basic data structures like lists, tuples, dictionaries, etc. Some knowledge of tkinter - Graphical User Interface (GUI) package that is bundled with Python, Some experience with object oriented programming is beneficial but not necessary . | A very versatile text editor (ironic that one needs one to build one :D) like Visual Studio Code (VSC), Atom, Sublime or any editor of your choice. I personally prefer VSC since it has myriad extensions to make your life easy . | Willingness to learn something new, there are instances where it gets a bit repetitive while defining functionality for various features in the editor and one may feel the need to simply copy-paste those sections from the source code but do remember that doing so does hamper one’s learning . | . Features of the Text Editor: . A toolbar which houses the Bold, italic, alignment options and other basic text editing features . | A status bar for counting words and characters . | The new file, open, save, save-as, exit functionalities common to most applications. . | Multiple colour themes . | . Experience . I decided to name my text editor Brief , a name shared by a once-popular programmer’s text editor in the 1980s and early 1990s. . The prerequisite knowledge helped me in grasping the concepts explained in the video quite easily. The content delivered was simple and to the point with little to no shift from the main goal of the tutorial i.e. coding a text editor. In my personal opinion, a Python novice too can easily build this software with a bit of extra effort. . The great thing about this tutorial is that towards the end, the creator walks you through the process of taking the python script and converting it into a executable (.exe), which can be placed on your desktop and may replace a basic text editor. I would personally recommend using pyinstaller package rather than the cx_freeze package to make an executable. Pyinstaller is easier to use and does not requires a lot of effort. Just remember to use the correct flags to generate your desired outputs. . A few screenshots of the editor: . First screen . Dark Theme . . Scope for improvement . The bold, italic and underline buttons can have their functionality improved by incorporating selective highlighting. . | Functionality to add tables and charts in the editor. . | Functionality to export the .txt files to other extensions. . | . I thoroughly enjoyed coding the program and would be actively looking to code similar programs in the near future. I will share my experiences via this blog. . Resources . - Source Code . - Youtube Video . - Pyinstaller Package . - VSC Download . - My GitHub .",
            "url": "https://shlok2002.github.io/blog/python/software%20development/2022/12/12/Python-editor.html",
            "relUrl": "/python/software%20development/2022/12/12/Python-editor.html",
            "date": " • Dec 12, 2022"
        }
        
    
  
    
        ,"post12": {
            "title": "Quant Funds",
            "content": "Introduction . Mutual funds have been here for a long time now. Each fund is a particular category, like flexicap, multi-cap, large-cap, arbitrage, etc. One such fund category that is relatively new is the Quant Fund category. Quant funds have been here for less than a decade but have sure beaten decade-old mutual funds in terms of return on investments! . What are quant funds? . Quant funds are a special kind of mutual fund whose asset allocation, including stock picking, is decided based on a predefined set of rules. They are built with customised models using software programs to determine investments. These funds are part active and part passive and are taxed according to equity funds. Choosing investments using inputs and computer programs helps fund companies reduce the risks and losses associated with management by human fund managers. . How does a quant fund work? . Quant funds rely on algorithmic or systematically programmed investment strategies. They use quantitative rather than fundamental analysis, which is why they’re also called quantitative funds. These algorithms are often proprietary and a heavily guarded secret for certain fund houses. One such example is ‘Quant Mutual Fund.’ The funds offered by this fund house have repeatedly created a more significant alpha and beaten the broader markets consistently. . Greater access to a broader range of market data fueled the growth of quant funds, not to mention the growing number of solutions surrounding the use of big data. Developments in financial technology and increasing innovation around automation have vastly broadened the data sets quant fund managers can work with, giving them even more robust data feeds for a broader analysis of scenarios and time horizons. . qAdvantages of quant funds . They limit human intervention and maintain a neutral investing attitude | Lower chances of error than traditional investing | Lower management fees due to reduced human intervention | Better risk-adjusted returns since calculations are on point and evolve with the dynamic conditions of the market | . Disadvantages of quant funds . Require continuous testing to validate forecasts | Some models may fail to account for black swan events | Models assume too many assumptions, which may result in different risk-adjusted returns | . Conclusion . If you think of quant funds as a straightforward manner to earn high returns, then you may be disappointed as they don’t assure returns. Most models are based on historical data with little to no guarantee of future returns. Quant funds can fail as they are primarily based on historical events, and the past doesn’t always repeat itself in the future. However, these funds ensure that the fund managers never deviate from the investment mandate. . . FAQs . How do you invest in Quant Funds? . Quant funds can be bought from the fund house like any other regular fund. there is no special application for the same. . Which AMCs offer Quant Funds? . Quant Mutual Fund, Axis Mutual Fund, and DSP Mutual Fund all have quant funds as an offering to the potential investors . Can Quant Funds beat other funds? . Quant funds are known to beat other funds by a large margin, but this is due to the fact that these funds have a high churn ratio. A higher churn ratio often leads to larger fees due to repeated buying and selling. These charges may sometimes eat up your alpha. .",
            "url": "https://shlok2002.github.io/blog/finance/mutual%20funds/2022/12/08/Quant-Funds.html",
            "relUrl": "/finance/mutual%20funds/2022/12/08/Quant-Funds.html",
            "date": " • Dec 8, 2022"
        }
        
    
  
    
        ,"post13": {
            "title": "Creating Wealth",
            "content": ". If you don’t find a way to make money while you sleep, you will have to work till you die - Warren E. Buffet Introduction . When are you buying that dream home of yours? When is it that you plan on taking your family for a vacation? To successfully do either of these, one requires money; this ultimately comes from your wealth creation. Wealth? What, How, and Where are the questions we answer here today. . What is wealth creation? . zWealth creation is investing in different asset classes where the investments will help fulfil critical needs. These investments should also be self-contained, stable, income-generating, and help one achieve their aspirations. . The wealth creation process will be most effective if started early. Starting investments during the early stages of life will give a head start on achieving goals. It also helps in generating higher growth in the long term. This is due to the power of compounding. The power of compounding is a concept that will help build a considerable future corpus. The idea of compounding revolves around reinvesting the returns into the fund to earn higher growth. Therefore, the longer one stays invested, the higher the wealth gain. . Why is wealth creation important? . Wealth creation is essential for several reasons: . It provides you with money to fulfil your future goals. | It offers a steady flow of income even when you are no longer employed or working. This can be a great way to ensure financial stability and help your loved ones continue living a life of comfort, abundance, and security. | Retirement can be a challenging phase with increasing medical and daily expenses. However, with wealth creation, you will never experience a financial crunch and be independent for as long as you live. | Strategies to Create Wealth . There are countless ways to get wealthy. However, the most common and accessible of those is to leverage the true potential of compound interest in one form or another. If you intend to become wealthy fast, you need to understand the risk-reward mechanism. The higher the gain, the higher the risk. With that in mind, here are the ways for you to build wealth in increasing order of the returns . Low-Risk Investments: Grow your money at almost no risks . Fixed Deposits | General Insurance and ULIPs | National Pension Scheme | Sovereign Gold Bonds | Fixed Income Instruments | . Medium Risk Investments: Higher Returns than safe investors . Mutual Funds | High-rated Corporate Bonds | P2P lending | . High-Risk Investments: Risk appetite must be very high . Equity mutual funds | Stocks | ETFs | Global Equities | Startup funding | Digital assets | . Bottom Line . Wealth creation is simple and easy when done right. Discipline and commitment to investing is the key to creating wealth. Starting early in the career will help multiply returns by taking advantage of the power of compounding. Wealth creation is a continuous process. You need to make a plan and stick to it to meet all your goals. Plus, there is no one-size-fits-all wealth creation solution as each individual has unique objectives, risk tolerance, etc. So, choosing the suitable investment to help you achieve your goals is critical in ensuring you succeed in creating wealth over time. . . FAQs . What is the first step in wealth creation? . Like any other activity, you need a plan to create wealth. This is a financial plan which is usually made with the help of a financial advisor and helps you in your wealth creation journey. . How to earn a stable income via wealth creation? . One can invest in dividend-yielding stocks, buy bonds which pay out regular interests, etc. .",
            "url": "https://shlok2002.github.io/blog/finance/investment%20101/2022/12/04/Creating-wealth.html",
            "relUrl": "/finance/investment%20101/2022/12/04/Creating-wealth.html",
            "date": " • Dec 4, 2022"
        }
        
    
  
    
        ,"post14": {
            "title": "Financial Planning",
            "content": "Introduction . Financial planning is a comprehensive evaluation of an individual’s current pay and future financial state using known variables to predict future income, asset values, and withdrawal plans. In other words, it is a step-by-step approach to meeting one’s life goals. Planning begins with a thorough evaluation of the person’s current financial state and future expectations and may be created independently or with the help of a certified financial planner. . Steps to Build the plan . What is my net worth? . Your net worth is the difference between your assets and liabilities. . Assets: Real Estate, Cars, Savings in the bank, Precious metals and stones, Investments, PPFs, EPFs. | Liabilities: Credit Card Debt, Home loans, Student debt, Mortgages. | . A positive net worth indicates you have more assets than your liabilities. If you have a negative net worth, your immediate plan should be to reduce your liabilities and improve your current financial health. Sound financial planning requires a positive net worth. . What are my goals? . What is the ultimate aim of this financial plan? Is it retirement? Is it a child’s education? One must have a clear goal before charting a strategy to achieve the same. These goals could be further divided based on their urgency/ timing. An example could be . Short Term: Buying a car, getting married | Medium Term: Foreign Vacation | Long Term: Educating and marrying kids, retirement | . How much money do I need? . This is the end-term amount required to lead an independent life. This is usually post-retirement when you do not draw a fixed salary and are dependent on your investments. These could be Systematic Withdrawal Plans, Unit Linked Insurance Plans (ULIPs), dividends from shares, real estate rent, etc. Estimate the figure by factoring in the inflation. This figure would greatly depend on your current financial health. . How much risk can I take? . Risk and reward go hand in hand. Striking a balance between the two is essential for realising your plan. High, medium, or low risk will depend on age, liabilities, income, dependents, investments, and work area. . Where should I invest? . When planning for the future, choosing a suitable asset class is work half done. Planning and execution is a lifelong skill and takes years to master. Investment is a similar skill that requires precise planning and execution. The decisions you make today have a significant impact on your future returns. The easiest way to ease this panning process is by investing via mutual funds. A mutual fund is a financial instrument wherein capital from many investors is pooled to form an investment product. The fund manager then supports across financial instruments to realise the fund’s investment goal. Check out this blog to choose the best mutual funds! Equity mutual funds are an excellent way to generate long-term, inflation-beating returns. . Long-term wealth creation is not a linear process. There are multiple ups and downs along the journey. These events can sometimes span for several months or even years. It is of utmost importance to have an asset that is seldom influenced by the market and acts as an excellent store of value. Tis Gold! . Seasoned investors have always regarded gold as a safe-haven asset. It has an excellent store of value and often acts as a hedge against inflation. However, physical gold has its limitations; . It is not readily liquid | It is prone to theft and damage | Initial investing value is very high | . Digital Gold is an online Gold alternative which enables you to hold gold virtually without owning a safe or bank locker. The seller keeps an equivalent weight of physical gold in a secure vault for each online purchase. . Insurance is another financial instrument that is a must-have in your plan. It offers you a protective financial cover against the various contingencies in life. For the many uncertainties that life throws your way, there are different types of insurance that you can bank on. Primarily, insurance for individuals is categorised as Life Insurance and General Insurance. Life Insurance offers a cover on the life of the policyholder. General Insurance, on the other hand, comes in many different forms. Motor Insurance for your vehicles, Home Insurance for your house, and even Travel Insurance for your vacations or business travels. And most importantly, there’s Health Insurance, which offers you a bankable cover for medical emergencies. . Bottom-line . Financial planning is all about getting your finances right. It is an evolving process and requires constant checks over its course. Furthermore, there is no ‘one model fits all’ when planning for the future. Most plans must be tailor-made to an individual’s requirements and require time and effort. This is where the role of a financial advisor comes in. They are responsible for planning and helping you realise your goals. So the next time you decide to buy that new phone on the market, wait, take a deep breath and think, do you need it? Or could you save up and plan your finances! . . FAQs . What is the right time to make a financial plan? . There is no right time per se. The earlier you plan the better your chances of realising your goals. Furthermore, you must have some tangible salary/amount to start off with. . Who can be a financial advisor? . It is imperative to look for individuals who are SEBI registered financial advisors. They are well versed in the process of making a plan and getting the best ROIs for you. .",
            "url": "https://shlok2002.github.io/blog/finance/2022/11/26/Financial_planning.html",
            "relUrl": "/finance/2022/11/26/Financial_planning.html",
            "date": " • Nov 26, 2022"
        }
        
    
  
    
        ,"post15": {
            "title": "What is digital gold?",
            "content": "Introduction . Gold has been a reliable investment option and a symbol of wealth since ages, getting passed on from mothers and grandmothers down to the younger generations. It is believed that all of the gold present in the earth’s crust has been mined; there is very little possibility of finding more reserves of this metal and hence it is deemed to be precious. All the gold available to us today is in circulation and hence there is no ‘store’ from which ‘new’ gold can be added into circulation. This has resulted in gold having tremendous store value and hence is considered very stable in terms of its returns. . Digital Gold is the new, and much more efficient iteration of storing this lustrous asset. This risk-free, storage-proof investment instrument is a perfect blend of both technology and the traditional importance Gold has. . What is Digital Gold? . Before going any further, it’s important to cover this question. Digital gold is an online Gold alternative which enables you to hold gold virtually without owning a safe or bank locker. The seller keeps an equivalent weight of physical gold in a secure vault for each online purchase. . Benefits of Adopting Digital Gold . Taxation: Returns on digital gold assets held for less than 36 months are not strictly taxable. In the case of long-term capital gains, one would have to pay a 20 percent tax on the whole amount, plus a surcharge and a 4% cess with indexation benefits. This is great for investors who want to build an emergency fund in the short to medium term. | Storage: One does not have to pay bank locker rent, insurance cover or additional investment of Fixed Deposit (FD). The seller promises that the digital gold is stored in an insured, secured vault at no extra cost. | Liquidity: Digital gold can be sold or redeemed at the click of a button. You can sell the digital gold instantly and the value of your gold is instantly transferred into your bank account through a 24x7 market-linked rate. | Portfolio Diversification: It is a good investment option for portfolio diversification and a good hedge asset. Making charges: Gold in jewellery form attracts at least 8%, making charges and the price of gold while buying it. This increases the buying cost and depreciation of returns; thus, investors now tend to buy digital gold free from any form of making charges. | Invest in small amounts: There is no minimum threshold to buy digital gold. One can start investing with as low as INR 10. This surely helps in accumulating assets over a long period of time. | . Digital gold is the perfect instrument to begin your investment journey. It is a great way to create robust long-term wealth. One can invest in fractions as low as INR 10 and there is no cap on your investment too. . Parting Words . In a time where investments are subject to market risks, the yellow metal has always emerged as a consistent performer. With wider adoption of digitalisation, digital gold stands a very strong chance to emerge as a powerful investment instrument. . . FAQs . Who holds onto the gold when I invest digitally? . Backing for the physical gold is provided by the following players: . Augmont Limited, a joint venture between state-owned Metals and Minerals Trading Corporation of India (MMTC) and Produits Artistiques Métaux Précieux, Switzerland (PAMP) SafeGold brand of Digital Gold India Pvt. Ltd. . Can I redeem my digital asset into physical form? . Yes, one can redeem his/her digital gold into physical form by requesting for physical delivery of the same. Do keep in mind that you would have to pay making charges for the same. . What are the costs associated with owning digital gold? . One has to pay 3% GST when placing the order to buy digital gold. .",
            "url": "https://shlok2002.github.io/blog/finance/digital%20gold/2022/10/14/digital-gold.html",
            "relUrl": "/finance/digital%20gold/2022/10/14/digital-gold.html",
            "date": " • Oct 14, 2022"
        }
        
    
  
    
        ,"post16": {
            "title": "Types of mutual funds",
            "content": "Ever wondered what’s a guaranteed path to get rich? What looks like a straight path is a simple two-step process - saving and investing. Saving is the easier of the two steps, but when it comes to investing, one, people have apprehensions, and two, there is risk involved. Mutual Funds are an excellent way to tackle this risk and grow wealth over time. . This blog aims to inform you about the various types of mutual funds categorized on the following grounds: . Structure | Asset Class | Investment Goals | Risk Appetite | Specialised Funds | . Based on Structure . Open-Ended Funds: These funds do not limit when or how many units can be purchased. Investors can enter or exit at the current net asset value (NAV) throughout the year. These funds are ideal for investors seeking liquidity. E.g., All funds that are not listed on the exchanges. | Close-Ended Funds: The unit capital to invest is pre-defined in closed-ended funds. The fund company cannot sell more than the pre-agreed number of units. To facilitate liquidity, these funds trade on stock exchanges. E.g., Exchange Traded Funds (ETFs) | Interval Funds: These are a mixture of both open-ended and close-ended schemes. These funds are open for purchase or redemption only during specific intervals (decided by the fund houses) and are closed the rest of the time. They also have a lock-in period of two years after the initial purchase. These funds are predominantly debt-oriented. E.g. IDFC Yearly Series Interval Fund. | Based on Asset Class . Equity Funds: Equity funds primarily invest in stocks. They invest the money pooled from various investors from diverse backgrounds into shares/supplies of different companies. The gains and losses associated with these funds depend solely on how the invested shares perform in the stock market. E.g.: Axis Bluechip Fund | Debt Funds: They invest in various fixed income instruments such as Fixed Maturity Plans (FMPs), Gilt Funds, Liquid Funds, Short-Term Plans, Long-Term Bonds and Monthly Income Plans, among others. Great for investors looking for passive income over fixed durations. E.g.: Aditya Birla Sun Life Liquid Fund | Hybrid Funds: As the name suggests, Hybrid or Balanced Funds are an optimum mix of bonds and stocks, thereby bridging the gap between equity funds and debt funds. The ratio can either be variable or fixed. E.g.: Kotak Equity Hybrid Fund | Based on Investment Goals . Growth Funds: Funds that invest primarily in high-performing stocks with the aim of capital appreciation are considered growth funds. These funds can be an attractive option for investors seeking high returns over a long period. E.g., Mirae Asset Emerging Bluechip Fund | Tax Saving Funds: Equity-linked saving schemes are mutual funds that invest primarily in company securities. However, they qualify for tax deductions under Section 80C of the Income Tax Act. They have a minimum investment horizon of three years. E.g., L&amp;T Tax Advantage Fund | Capital Protection Funds: These funds invest partially in fixed income instruments and into equities. This could ensure capital protection, i.e., minimal loss, if any. However, returns are taxable. E.g., SBI CPO Fund | Based on Risk Appetite . Very Low-Risk Funds: Liquid and ultra-short duration funds are considered very-low risk funds. Their returns are low (6% at best). Investors usually park their surplus cash in such funds until they find better investment opportunities. E.g.: Nippon India Ultra Short Duration Fund | Low-risk Funds: Arbitrage funds are considered low-risk funds. They have minimal exposure to equities and high-risk asset classes. These are best suited for risk-averse investors, and again the returns are 6-8% on average. Eg: Tata Arbitrage Fund | Medium-Risk Funds: Such funds have considerable exposure to equities. These funds are very similar to index funds and give moderate returns in the range of 9-12% E.g., Kotak Savings Funds | High-Risk Funds: These funds have maximum stock exposure (&gt;95%). The NAV for these funds is volatile too. Moreover, these funds are best suited for young people who have a higher risk appetite. Returns are upwards of 15%, often beating the indexes they track. Some funds also give returns of above 20% E.g., Quant small-cap funds | Specialised Funds . Sector Funds: Sector funds invest solely in a specific sector. They are theme-based funds. If investors want to leverage sectoral trends, they can invest via this route. E.g., BOI AXA Manufacturing &amp; Infrastructure Fund | Index Funds: These are passive funds with very low expense ratios. They track an index and invest according to the constituents of the same. They are great for investors seeking moderate returns. They may or may not beat the index. E.g., UTI Nifty Index Fund | Fund of Funds: These are special mutual funds that invest in units of other mutual funds. Most global funds available in India are of this type. In short, you are buying a fund that invests in additional diverse funds. E.g., ICICI Prudential Asset Allocator Fund (FoF) | International Funds: These funds invest in companies outside India. Investors seeking international exposure may consider these funds. E.g., Motilal Oswal S&amp;P 500 Index Fund | Exchange-Traded Funds: These belong to the index fund family. They are close-ended and trade on the exchanges. They give exposure to broader markets as well as specific sectors. E.g., SBI Nifty IT ETF | . FAQs . What are regular and direct options in mutual funds? . When one invests via a mutual fund distributor, one invests in regular funds. Regular funds tend to have a higher expense ratio to compensate for the commission paid by the AMC to the distributor. On the other hand, direct plans have a lower expense ratio as there is no intermediary; you engage directly with the fund house. If you invest via your financial advisor, a regular plan suits you; otherwise, a direct plan is much better to reduce expenses. . Are returns guaranteed in mutual funds? . Most AMC has a disclosure that the fund may fail to achieve its goals, and hence one should perform proper due diligence before investing. . What is the IDCW option in funds? . IDCW stands for Income Distribution cum Withdrawal. These are plans where the AMC periodically distributes profit to its unitholders via the declaration of annual dividends. These are suitable for people looking for a regular income stream from their investments. .",
            "url": "https://shlok2002.github.io/blog/mutual%20funds/finance/2022/09/23/tyes-of-mutual-funds.html",
            "relUrl": "/mutual%20funds/finance/2022/09/23/tyes-of-mutual-funds.html",
            "date": " • Sep 23, 2022"
        }
        
    
  
    
        ,"post17": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://shlok2002.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post18": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://shlok2002.github.io/blog/2020/01/14/test-markdown-post.html",
            "relUrl": "/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Shlok Kamat . Analytics, Finance and Green Energy . TECHNICAL SKILLS . Programming/Data Science: SQL (Postgres, MySQL), Python (pandas, numpy, scikit-learn, matplotlib, seaborn, NetworkX), R . BI/Cloud: Tableau, Vertex-AI on Google Cloud Platform (Auto-ML) . KEY STRENGTHS . Operational, Product and Data Analytics | Content Strategy and Business Development | Stakeholder Management and Sales Presentation | . . I am an undergraduate student at Shiv Nadar Institution of Eminence majoring in electrical and electronics engineering. At university, I research modern machine learning algorithms for applications in content creation, finance, and energy analytics. I enjoy performing exploratory data analyses on public data sets and creating beautiful and intuitive visualisations. I am interested in leveraging the power of data to solve complex business problems in renewable energy and green finance. . I have a diverse portfolio of work experiences in technical, business and marketing segments from my internships. I thrive in entrepreneurial environments collaborating with cross-functional and dynamic teams, solving complex problems. . Outside academics, I am an F1 racing fan. I am intrigued by finance and think of myself as a long-term investor. I enjoy reading about a variety of topics. I am best reached by email at ks649@snu.edu.in. Feel free to reach out about my research or anything else I might be able to help with. . .",
          "url": "https://shlok2002.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://shlok2002.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}