{
  
    
        "post0": {
            "title": "What is an NFT?",
            "content": "Jack Dorsey sells his first tweet ever as an NFT for $2.9 million, read the headline of major business newspapers on 24th March 2021. A year later, Twitter is going private, all thanks to Elon Musk, in what is said to be the largest Leveraged buyout (LBO) ever. Both Jack Dorsey and Elon Musk are successful entrepreneurs who have voiced their support for the Blockchain Revolution. This revolution is not going away anytime soon! Let’s get back to the question, can you sell a tweet? How do you do it, and what is that N-F-T doing there in the headline? . What is an NFT? . NFT stands for Non-Fungible-Token; non-fungible means something that cannot be exchanged for an item because it is unique. In other words, you can exchange a ₹100 note for another ₹100 note as both have the same value associated with them. Another classic example is a cryptocurrency; 1 Bitcoin can be exchanged for another. Cryptocurrency is fungible, whereas NFTs are not. On the other hand, one piece of artwork is not equal to another; The Mona Lisa is not equal to a Van Gogh’s since both have unique properties. NFTs are tokens that live on a blockchain and represent ownership of unique items. Why do you need a blockchain to do this? Well, tracking a digital file is tricky, as it can be copied and distributed effortlessly. A blockchain comes in handy for ease of tracking ownership and for the value discovery of an asset. Let us take an example to cement our understanding. . Suppose you made a piece of digital art. You can create a .jpg or mint an NFT out of this. The NFT that represents your art contains information about it, such as . A unique fingerprint ID of the file (Hash) . | Token Name . | Token Symbol . | . This token is then stored on the blockchain, and you, the artist, become the owner. To sell the artwork, you create a transaction on the blockchain, and the blockchain makes sure that this information can never be tampered with. It also allows you to track the current owner if the artwork is traded further. In other words, it is a smart contract on the blockchain that stores the unique properties of the asset and keeps track of current and previous owners. . Specifics of an NFT . It is important to note that the artwork itself is not stored in the blockchain; only its attributes like hash, name and a link to the actual artwork are stored in the block. Also, one must keep in mind that you often do not get a physical copy of the original artwork and most of the time, anyone can download a physical copy for free. The NFT only represents proof of ownership. It gives you exclusive ‘digital bragging rights. . NFTs are not limited to pieces of digital artwork, though a bulk of the market comprises these; NFTs can also include concert tickets, domain names, in-game limited edition items, real estate and anything that is unique and requires proof of ownership. The prices of NFTs are not uniform and depend on supply-demand characteristics. A word of caution: an expensive NFT becomes worthless if no one wants to buy it! . . FAQs . Where can one buy NFTs? . NFTs can be bought online on open-source exchanges and NFT marketplaces. . Which blockchain is used in NFTs? . A bulk of contracts are executed on the Ethereum blockchain. .",
            "url": "https://shlok2002.github.io/blog/web3/2022/12/21/What-is-NFT.html",
            "relUrl": "/web3/2022/12/21/What-is-NFT.html",
            "date": " • Dec 21, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Market Basket Analysis (MBA)",
            "content": ". Understanding MBA . Market basket analysis (MBA), also known as association-rule mining, is a useful method of discovering customer purchasing patterns by extracting associations or co-occurrences from stores&#39; transactional databases (Chen et al., 2005). It is a modelling technique based upon the theory that if you buy a certain group of items, you are more (or less) likely to buy another group of items. For example, if you are in a supermarket and you buy a loaf of Bread, you are more likely to buy a packet of Butter at the same time than somebody who didn&#39;t buy the Bread. Another example, if you are buying a XiaoMi Power Bank in an online store, you are more likely to also buy a carrying case to go with the power bank. Amazon knows this well from the transaction data of its millions of customers and thus recommends a case to you as seen below: . | . Credit: Amazon . The set of items a customer buys is known as an itemset, and MBA tries to identify relationships from the purchases of itemset. The output of MBA consists of a series of product association rules. From the transaction data extracted from the shopping carts of online retailers or the point of sales system of retail stores, we can use MBA to extract interesting association rules between products. For example, if customers buy product A they also tend to buy product B. . Typically we can extract the relationship between products in the form of a rule, an example of association rule: . IF {bread} THEN {butter}. . In this example, if customers buy Bread they also tend to buy Butter. Some people often link products with high association to &quot;complementary goods&quot;. In Economics 101, complementary good or service is consumed or used in conjunction with another good or service. Usually, the complementary good has little to no value when consumed alone, but when combined with another good or service, it adds to the overall value of the offering. For example a car and petrol. It would be of little value to buy petrol without owning a car. Complementary goods often have a negative cross-price elasticity of demand coefficient (Farnham, 2014). However, it is worth pointing out that, while complementary goods tend to have high association, not all products with high association rules are complementary goods. In MBA, we are more interested in product-pairs with high association rules i.e. products that are frequently purchased together. For example, in a retail store, MBA findings may show that Barbie dolls and candy are frequently purchased together, even though they are not technically complementary goods. In short, complementary goods are fairly obvious and common sense, but MBA seeks to uncover product associations that may not be so obvious and straighforward. In doing so, it is attempting to convert the abstract consumer tastes and preferences into association rules that are more insightful and actionable, from business perspective. . . Applications . There are many real-life applications of MBA: . Recommendation engine – showing related products as &quot;Customers Who Bought This Item Also Bought&quot; or “Frequently bought together” (as shown in the Amazon example above). It can also be applied to recommend videos and news article by analyzing the videos or news articles that are often watched or read together in a user session. | Cross-sell / bundle products – selling associated products as a &quot;bundle&quot; instead of individual items. For example, transaction data may show that customers often buy a new phone with screen protector together. Phone retailers can then package new phone with high-margin screen protector together and sell them as a bundle, thereby increasing their sales. | Arrangement of items in retail stores – associated items can be placed closer to each other, thereby invoking &quot;impulse buying&quot;. For example it may be uncovered that customers who buy Barbie dolls also buy candy at the same time. Thus retailers can place high-margin candy near Barbie doll display, thereby tempting customers to buy them together. | Detecting fraud – identifying related actions whenever a fraudulent transaction is performed. For example, in a fraudulent insurance claim for stolen vehicle, it may be analyzed (from historical data) that claimant frequently report the incident a few days late (action 1) and often refuse to cooperate with insurer on investigation (action 2). Insurers can identify these red flags once certain behaviours or actions are displayed by the claimants. | . . Case Study . For simplicity we are analyzing only 2 items – Bread and Butter. We want to know if there is any evidence that suggests that buying Bread leads to buying Butter. . Problem Statament: Is the purchase of Bread leads to the purchase of Butter? Hypothesis: There is significant evidence to show that buying Bread leads to buying Butter. . Bread =&gt; Butter . Antecedent =&gt; Consequent . Let&#39;s take the example of a supermarket which generates 1,000 transactions monthly, of which Bread was purchased in 150 transactions, Butter in 130 transactions, and both together in 50 transactions. . In set theory it can be represented as Bread only – 100, Butter only – 80, Bread and Butter – 50, as shown in the Venn diagram below: . . Analysis and Findings . We can use MBA to extract the association rule between Bread and Butter. There are three metrics or criteria to evaluate the strength or quality of an association rule, which are support, confidence and lift. . 1. Support . Support measures the percentage of transactions containing a particular combination of items relative to the total number of transactions. In our example, this is the percentage of transactions where both Bread and Butter are bought together. We need to calculate this to know if this combination of items is significant or negligible? Generally, we want a high percentage i.e. high support in order to make sure it is a useful relationship. Typically, we will set a threshold, for example we will only look at a combination if more than 1% of transactions have this combination. . Support (antecedent (Bread) and consequent (Butter)) = Number of transactions having both items / Total transactions . . Result: The support value of 5% means 5% of all transactions have this combination of Bread and Butter bought together. Since the value is above the threshold of 1%, it shows there is indeed support for this association and thus satisfy the first criteria. . . 2. Confidence . Confidence measures the probability of finding a particular combination of items whenever antecedent is bought. In probability terms, confidence is the conditional probability of the consequent given the antecedent and is represented as P (consequent / antecedent). In our example, it is the probability of both Bread and Butter being bought together whenever Bread is bought. Typically, we may set a threshold, say we want this combination to occur at least 25% of times when Bread is bought. . Confidence (antecedent i.e. Bread and consequent i.e. Butter) = P (Consequent (Butter) is bought GIVEN antecedent (Bread) is bought) . . Result: The confidence value of 33.3% is above the threshold of 25%, indicating we can be confident that Butter will be bought whenever Bread is bought, and thus satisfy the second criteria. . . 3. Lift . Lift is a metric to determine how much the purchase of antecedent influences the purchase of consequent. In our example, we want to know whether the purchase of Butter is independent of the purchase of Bread (or) is the purchase of Butter happening due to the purchase of Bread? In probability terms, we want to know which is higher, P (Butter) or P (Butter / Bread)? If the purchase of Butter is influenced by the purchase of Bread, then P (Butter / Bread) will be higher than P (Butter), or in other words, the ratio of P (Butter / Bread) over P (Butter) will be higher than 1. . . Result: The lift value of 2.56 is greater than 1, it shows that the purchase of Butter is indeed influenced by the purchase of Bread rather than Butter&#39;s purchase being independent of Bread. The lift value of 2.56 also means that Bread&#39;s purchase lifts the Butter&#39;s purchase by 2.56 times. . . Conclusion . Based on the findings above, we can justify our initial hypothesis as we . a) Have the support of 5% transactions for Bread and Butter in the same basket b) Have 33.3% confidence that Butter sales happen whenever Bread is purchased. c) Knows the lift in Butter&#39;s sales is 2.56 times more, whenever Bread is purchased than when Butter is purchased alone. . Therefore, we can conclude that there is indeed evidence to suggest that the purchase of Bread leads to the purchase of Butter. This is a valuable insight to guide management&#39;s decision-making. For example, managers of retail stores could start placing bread and butter close to each other, knowing that customers are highly likely to &quot;impulsively&quot; purchase them together, thereby increasing the store&#39;s revenue. . . Implementation in Python . While it is possible to use Ms Excel to calculate support, confidence and lifts, doing so on a large dataset with thousands of different combination of items can be a daunting task. Therefore, we will be resorting to Python libraries for a ready-made algorithm. Unfortunately, the popular scikit-learn library does not support this algorithm. Fortunately, we can use another library called MLxtend (machine learning extensions) by Sebastian Raschka which has an implementation of the Apriori algorithm for extracting frequent item sets for further analysis. Chris Moffitt has an awesome tutorial on using MLxtend which this project draws on. . If you are using Jupyter Notebook, the MLxtend library does not come pre-installed with Anaconda, but you can easily install this package with conda, just run one of the following in your Anaconda Prompt: conda install -c conda-forge mlxtend conda install -c conda-forge/label/gcc7 mlxtend . Dataset . The dataset that is used in this project is publicly available from Kaggle which contains the Transactions data from a bakery from 30/10/2016 to 09/04/2017. The data belongs to a bakery called &quot;The Bread Basket&quot; that serves coffee, bread, muffin, cookies and so on. It is located in the historic center of Edinburgh. . | . Credit: Kaggle . Import libraries . %matplotlib inline import numpy as np import pandas as pd import matplotlib.pyplot as plt from mlxtend.frequent_patterns import apriori from mlxtend.frequent_patterns import association_rules . Load data . bread = pd.read_csv(&quot;BreadBasket_DMS.csv&quot;) bread.head(10) . Date Time Transaction Item . 0 2016-10-30 | 09:58:11 | 1 | Bread | . 1 2016-10-30 | 10:05:34 | 2 | Scandinavian | . 2 2016-10-30 | 10:05:34 | 2 | Scandinavian | . 3 2016-10-30 | 10:07:57 | 3 | Hot chocolate | . 4 2016-10-30 | 10:07:57 | 3 | Jam | . 5 2016-10-30 | 10:07:57 | 3 | Cookies | . 6 2016-10-30 | 10:08:41 | 4 | Muffin | . 7 2016-10-30 | 10:13:03 | 5 | Coffee | . 8 2016-10-30 | 10:13:03 | 5 | Pastry | . 9 2016-10-30 | 10:13:03 | 5 | Bread | . bread.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 21293 entries, 0 to 21292 Data columns (total 4 columns): Date 21293 non-null object Time 21293 non-null object Transaction 21293 non-null int64 Item 21293 non-null object dtypes: int64(1), object(3) memory usage: 665.5+ KB . Note: . . Check for Missing Values . bread.isnull().sum() . Date 0 Time 0 Transaction 0 Item 0 dtype: int64 . missing_value = [&quot;NaN&quot;, &quot;NONE&quot;, &quot;None&quot;, &quot;Nil&quot;, &quot;nan&quot;, &quot;none&quot;, &quot;nil&quot;, 0] print(&quot;There are {0} missing values in the dataframe.&quot;.format(len(bread[bread.Item.isin(missing_value)]))) bread[bread.Item.isin(missing_value)].head(10) . There are 786 missing values in the dataframe. . Date Time Transaction Item . 26 2016-10-30 | 10:27:21 | 11 | NONE | . 38 2016-10-30 | 10:34:36 | 15 | NONE | . 39 2016-10-30 | 10:34:36 | 15 | NONE | . 66 2016-10-30 | 11:05:30 | 29 | NONE | . 80 2016-10-30 | 11:37:10 | 37 | NONE | . 85 2016-10-30 | 11:55:51 | 40 | NONE | . 126 2016-10-30 | 13:02:04 | 59 | NONE | . 140 2016-10-30 | 13:37:25 | 65 | NONE | . 149 2016-10-30 | 13:46:48 | 67 | NONE | . 167 2016-10-30 | 14:32:26 | 75 | NONE | . Note: While there is no empty cell in the dataframe, a check using the popular missing value shows that there are 786 rows with &quot;NONE&quot; in the column Item. Since the items are not recorded, we will have to remove these rows. . bread = bread.drop(bread[bread.Item == &quot;NONE&quot;].index) print(&quot;Number of rows: {0}&quot;.format(len(bread))) bread.head(10) . Number of rows: 20507 . Date Time Transaction Item . 0 2016-10-30 | 09:58:11 | 1 | Bread | . 1 2016-10-30 | 10:05:34 | 2 | Scandinavian | . 2 2016-10-30 | 10:05:34 | 2 | Scandinavian | . 3 2016-10-30 | 10:07:57 | 3 | Hot chocolate | . 4 2016-10-30 | 10:07:57 | 3 | Jam | . 5 2016-10-30 | 10:07:57 | 3 | Cookies | . 6 2016-10-30 | 10:08:41 | 4 | Muffin | . 7 2016-10-30 | 10:13:03 | 5 | Coffee | . 8 2016-10-30 | 10:13:03 | 5 | Pastry | . 9 2016-10-30 | 10:13:03 | 5 | Bread | . Note: After removing the missing values, the number of rows left is 20,507 (original 21,293 minus 786 missing) . . Convert to DatetimeIndex . bread[&#39;Datetime&#39;] = pd.to_datetime(bread[&#39;Date&#39;]+&#39; &#39;+bread[&#39;Time&#39;]) bread = bread[[&quot;Datetime&quot;, &quot;Transaction&quot;, &quot;Item&quot;]].set_index(&quot;Datetime&quot;) bread.head(10) . Transaction Item . Datetime . 2016-10-30 09:58:11 1 | Bread | . 2016-10-30 10:05:34 2 | Scandinavian | . 2016-10-30 10:05:34 2 | Scandinavian | . 2016-10-30 10:07:57 3 | Hot chocolate | . 2016-10-30 10:07:57 3 | Jam | . 2016-10-30 10:07:57 3 | Cookies | . 2016-10-30 10:08:41 4 | Muffin | . 2016-10-30 10:13:03 5 | Coffee | . 2016-10-30 10:13:03 5 | Pastry | . 2016-10-30 10:13:03 5 | Bread | . Quick Stats . total_items = len(bread) total_days = len(np.unique(bread.index.date)) total_months = len(np.unique(bread.index.month)) average_items = total_items / total_days unique_items = bread.Item.unique().size print(&quot;There are {} unique items sold by the Bakery&quot;.format(unique_items)) print(&quot;Total {} items sold in {} days throughout {} months&quot;.format(total_items, total_days, total_months)) print(&quot;With an average of {} items sold daily&quot;.format(average_items)) . There are 94 unique items sold by the Bakery Total 20507 items sold in 159 days throughout 7 months With an average of 128.9748427672956 items sold daily . Note: We have combined the Date and Time columns into a single Datetime column, convert it into datetime64 type, and then set it as DatetimeIndex. This will make it easier to plot the time series charts later on. Also, a quick look at the data shows that the Bakery sold an average of 129 items daily. . . Visualization . bread.Item.value_counts(normalize=True)[:10] . Coffee 0.266787 Bread 0.162140 Tea 0.069976 Cake 0.049983 Pastry 0.041742 Sandwich 0.037597 Medialuna 0.030039 Hot chocolate 0.028771 Cookies 0.026332 Brownie 0.018481 Name: Item, dtype: float64 . bread.Item.value_counts(normalize=True)[:10].plot(kind=&quot;bar&quot;, title=&quot;Percentage of Sales by Item&quot;).set(xlabel=&quot;Item&quot;, ylabel=&quot;Percentage&quot;) . [Text(0,0.5,&#39;Percentage&#39;), Text(0.5,0,&#39;Item&#39;)] . bread.Item.value_counts()[:10].plot(kind=&quot;bar&quot;, title=&quot;Total Number of Sales by Item&quot;).set(xlabel=&quot;Item&quot;, ylabel=&quot;Total Number&quot;) . [Text(0,0.5,&#39;Total Number&#39;), Text(0.5,0,&#39;Item&#39;)] . Note: From the bar charts above, it is clear that Coffee (26.7%) is the best-selling item in the bakery, follow by Bread (16.2%) and Tea (7.0%). . bread[&quot;Item&quot;].resample(&quot;D&quot;).count().plot(figsize=(12,5), grid=True, title=&quot;Total Number of Items Sold by Date&quot;).set(xlabel=&quot;Date&quot;, ylabel=&quot;Total Number of Items Sold&quot;) . [Text(0,0.5,&#39;Total Number of Items Sold&#39;), Text(0.5,0,&#39;Date&#39;)] . Note: Total Number of Items Sold by Date fluctuates a lot thoughout the 159 days of data . bread[&quot;Item&quot;].resample(&quot;M&quot;).count() . Datetime 2016-10-31 369 2016-11-30 4436 2016-12-31 3339 2017-01-31 3356 2017-02-28 3906 2017-03-31 3944 2017-04-30 1157 Freq: M, Name: Item, dtype: int64 . bread[&quot;Item&quot;].resample(&quot;M&quot;).count().plot(figsize=(12,5), grid=True, title=&quot;Total Number by Items Sold by Month&quot;).set(xlabel=&quot;Date&quot;, ylabel=&quot;Total Number of Items Sold&quot;) . [Text(0,0.5,&#39;Total Number of Items Sold&#39;), Text(0.5,0,&#39;Date&#39;)] . Note: Given that the beginning month (October 2016) and ending month (April 2017) are not full month, the total number of items sold by month for the five full month between November 2016 to March 2017 does not fluctuate too much. . # For Datetimeindex, the day of the week with Monday=0, Sunday=6, thereby +1 to become Monday=1, Sunday=7 bread[&quot;Hour&quot;] = bread.index.hour bread[&quot;Weekday&quot;] = bread.index.weekday + 1 bread.head(10) . Transaction Item Hour Weekday . Datetime . 2016-10-30 09:58:11 1 | Bread | 9 | 7 | . 2016-10-30 10:05:34 2 | Scandinavian | 10 | 7 | . 2016-10-30 10:05:34 2 | Scandinavian | 10 | 7 | . 2016-10-30 10:07:57 3 | Hot chocolate | 10 | 7 | . 2016-10-30 10:07:57 3 | Jam | 10 | 7 | . 2016-10-30 10:07:57 3 | Cookies | 10 | 7 | . 2016-10-30 10:08:41 4 | Muffin | 10 | 7 | . 2016-10-30 10:13:03 5 | Coffee | 10 | 7 | . 2016-10-30 10:13:03 5 | Pastry | 10 | 7 | . 2016-10-30 10:13:03 5 | Bread | 10 | 7 | . bread_groupby_hour = bread.groupby(&quot;Hour&quot;).agg({&quot;Item&quot;: lambda item: item.count()/total_days}) bread_groupby_hour . Item . Hour . 1 0.006289 | . 7 0.150943 | . 8 4.056604 | . 9 12.364780 | . 10 16.767296 | . 11 19.509434 | . 12 17.949686 | . 13 16.459119 | . 14 16.603774 | . 15 13.301887 | . 16 8.446541 | . 17 2.314465 | . 18 0.515723 | . 19 0.301887 | . 20 0.138365 | . 21 0.018868 | . 22 0.050314 | . 23 0.018868 | . bread_groupby_hour.plot(y=&quot;Item&quot;, figsize=(12,5), title=&quot;Average Number by Items Sold by Hour of the Day&quot;).set(xlabel=&quot;Hour of the Day (24 hour time)&quot;, ylabel=&quot;Average Number of Items Sold&quot;) . [Text(0,0.5,&#39;Average Number of Items Sold&#39;), Text(0.5,0,&#39;Hour of the Day (24 hour time)&#39;)] . Note: Sales starts to pick up from 8am, till the busiest hour of the day at 11am, then slowly drops till the late afternoon. It can be observed that most of the sales transactions took place during the lunch hours of the day . bread_groupby_weekday = bread.groupby(&quot;Weekday&quot;).agg({&quot;Item&quot;: lambda item: item.count()}) bread_groupby_weekday . Item . Weekday . 1 2324 | . 2 2392 | . 3 2321 | . 4 2646 | . 5 3124 | . 6 4605 | . 7 3095 | . # in order to calculate the average items per weekday import datetime daterange = pd.date_range(datetime.date(2016, 10, 30), datetime.date(2017, 4, 9)) monday = 0 tuesday = 0 wednesday = 0 thursday = 0 friday = 0 saturday = 0 sunday = 0 for day in np.unique(bread.index.date): if day.isoweekday() == 1: monday += 1 elif day.isoweekday() == 2: tuesday += 1 elif day.isoweekday() == 3: wednesday += 1 elif day.isoweekday() == 4: thursday += 1 elif day.isoweekday() == 5: friday += 1 elif day.isoweekday() == 6: saturday += 1 elif day.isoweekday() == 7: sunday += 1 all_weekdays = monday + tuesday + wednesday + thursday + friday + saturday + sunday print(&quot;monday = {0}, tuesday = {1}, wednesday = {2}, thursday = {3}, friday = {4}, saturday = {5}, sunday = {6}, total = {7}&quot;.format(monday, tuesday, wednesday, thursday, friday, saturday, sunday, all_weekdays)) . monday = 21, tuesday = 23, wednesday = 23, thursday = 23, friday = 23, saturday = 23, sunday = 23, total = 159 . conditions = [ (bread_groupby_weekday.index == 1), (bread_groupby_weekday.index == 2), (bread_groupby_weekday.index == 3), (bread_groupby_weekday.index == 4), (bread_groupby_weekday.index == 5), (bread_groupby_weekday.index == 6), (bread_groupby_weekday.index == 7)] choices = [bread_groupby_weekday.Item/21, bread_groupby_weekday.Item/23, bread_groupby_weekday.Item/23, bread_groupby_weekday.Item/23, bread_groupby_weekday.Item/23, bread_groupby_weekday.Item/23, bread_groupby_weekday.Item/23] bread_groupby_weekday[&quot;Average&quot;] = np.select(conditions, choices, default=0) bread_groupby_weekday . Item Average . Weekday . 1 2324 | 110.666667 | . 2 2392 | 104.000000 | . 3 2321 | 100.913043 | . 4 2646 | 115.043478 | . 5 3124 | 135.826087 | . 6 4605 | 200.217391 | . 7 3095 | 134.565217 | . bread_groupby_weekday.plot(y=&quot;Average&quot;, figsize=(12,5), title=&quot;Average Number by Items Sold by Day of the Week&quot;).set(xlabel=&quot;Day of the Week (1=Monday, 7=Sunday)&quot;, ylabel=&quot;Average Number of Items Sold&quot;) . [Text(0,0.5,&#39;Average Number of Items Sold&#39;), Text(0.5,0,&#39;Day of the Week (1=Monday, 7=Sunday)&#39;)] . Note: Saturday is the busiest day of the week with the highest sales (~200 items) while Wednesday is the quietest day with the lowest sales (~101 items). This is an interesting insight, the owner of the Bakery should launch some promotion activities to boost up sales in the middle of the week when sales are slowest. . . One-Hot Encoding . The Apriori function in the MLxtend library expects data in a one-hot encoded pandas DataFrame. This means that all the data for a transaction must be included in one row and the items must be one-hot encoded. Example below: . Coffee Cake Bread Cookie Muffin Tea Milk Juice Sandwich . 0 | 0 | 1 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | . 1 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | . 2 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | . 3 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | . 4 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . Therefore, we&#39;ll need to group the bread dataframe by Transaction and Item and display the count of items. Then we need to consolidate the items into one transaction per row with each item one-hot encoded. . df = bread.groupby([&quot;Transaction&quot;,&quot;Item&quot;]).size().reset_index(name=&quot;Count&quot;) df.head() . Transaction Item Count . 0 1 | Bread | 1 | . 1 2 | Scandinavian | 2 | . 2 3 | Cookies | 1 | . 3 3 | Hot chocolate | 1 | . 4 3 | Jam | 1 | . basket = (df.groupby([&#39;Transaction&#39;, &#39;Item&#39;])[&#39;Count&#39;] .sum().unstack().reset_index().fillna(0) .set_index(&#39;Transaction&#39;)) basket.head() . Item Adjustment Afternoon with the baker Alfajores Argentina Night Art Tray Bacon Baguette Bakewell Bare Popcorn Basket ... The BART The Nomad Tiffin Toast Truffles Tshirt Valentine&#39;s card Vegan Feast Vegan mincepie Victorian Sponge . Transaction . 1 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 2 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 3 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 4 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 5 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | ... | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 5 rows × 94 columns . basket[basket.Coffee == 4].iloc[:,14:28] . Item Brownie Cake Caramel bites Cherry me Dried fruit Chicken Stew Chicken sand Chimichurri Oil Chocolates Christmas common Coffee Coffee granules Coke Cookies Crepes . Transaction . 6560 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 4.0 | 0.0 | 0.0 | 1.0 | 0.0 | . 6850 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 4.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 6887 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 4.0 | 0.0 | 0.0 | 0.0 | 0.0 | . Note: At this stage, the one-hot encoded table shows the count of items purchased as result. If you observe the portion of the table above, in Transaction 6887, the cell value for Coffee is &quot;4.0&quot; because there were 4 coffee purchased in this transaction. However, this is not important for us and we need to convert this value into 1. . def encode_units(x): if x &lt;= 0: return 0 if x &gt;= 1: return 1 . basket_sets = basket.applymap(encode_units) basket_sets.head() . Item Adjustment Afternoon with the baker Alfajores Argentina Night Art Tray Bacon Baguette Bakewell Bare Popcorn Basket ... The BART The Nomad Tiffin Toast Truffles Tshirt Valentine&#39;s card Vegan Feast Vegan mincepie Victorian Sponge . Transaction . 1 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 3 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 rows × 94 columns . basket_sets[basket_sets.Coffee == 1].iloc[3142:3145,14:28] . Item Brownie Cake Caramel bites Cherry me Dried fruit Chicken Stew Chicken sand Chimichurri Oil Chocolates Christmas common Coffee Coffee granules Coke Cookies Crepes . Transaction . 6884 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | . 6885 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | . 6887 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | . Note: After applying the encoding function, for the same Transaction 6887, the cell value for Coffee has become &quot;1&quot; which is what we need for the Apriori function. . . Generate Frequent Itemsets . Now, we are ready to generate the frequent item sets. We will set the minimum-support threshold at 1% . frequent_itemsets = apriori(basket_sets, min_support=0.01, use_colnames=True) . Generate Association Rules . The final step is to generate the rules with their corresponding support, confidence and lift. We will set the minimum threshold for lift at 1 and then sort the result by descending confidence value. . rules = association_rules(frequent_itemsets, metric=&quot;lift&quot;, min_threshold=1) rules.sort_values(&quot;confidence&quot;, ascending = False, inplace = True) rules.head(10) . antecedents consequents antecedent support consequent support support confidence lift leverage conviction . 31 (Toast) | (Coffee) | 0.033597 | 0.478394 | 0.023666 | 0.704403 | 1.472431 | 0.007593 | 1.764582 | . 29 (Spanish Brunch) | (Coffee) | 0.018172 | 0.478394 | 0.010882 | 0.598837 | 1.251766 | 0.002189 | 1.300235 | . 19 (Medialuna) | (Coffee) | 0.061807 | 0.478394 | 0.035182 | 0.569231 | 1.189878 | 0.005614 | 1.210871 | . 23 (Pastry) | (Coffee) | 0.086107 | 0.478394 | 0.047544 | 0.552147 | 1.154168 | 0.006351 | 1.164682 | . 1 (Alfajores) | (Coffee) | 0.036344 | 0.478394 | 0.019651 | 0.540698 | 1.130235 | 0.002264 | 1.135648 | . 16 (Juice) | (Coffee) | 0.038563 | 0.478394 | 0.020602 | 0.534247 | 1.116750 | 0.002154 | 1.119919 | . 25 (Sandwich) | (Coffee) | 0.071844 | 0.478394 | 0.038246 | 0.532353 | 1.112792 | 0.003877 | 1.115384 | . 7 (Cake) | (Coffee) | 0.103856 | 0.478394 | 0.054728 | 0.526958 | 1.101515 | 0.005044 | 1.102664 | . 27 (Scone) | (Coffee) | 0.034548 | 0.478394 | 0.018067 | 0.522936 | 1.093107 | 0.001539 | 1.093366 | . 12 (Cookies) | (Coffee) | 0.054411 | 0.478394 | 0.028209 | 0.518447 | 1.083723 | 0.002179 | 1.083174 | . Interpretation and Implications . The output above shows the Top 10 itemsets sorted by confidence value and all itemsets have support value over 1% and lift value over 1. The first itemset shows the association rule &quot;if Toast then Coffee&quot; with support value at 0.023666 means nearly 2.4% of all transactions have this combination of Toast and Coffee bought together. We also have 70% confidence that Coffee sales happen whenever a Toast is purchased. The lift value of 1.47 (greater than 1) shows that the purchase of Coffee is indeed influenced by the purchase of Toast rather than Coffee&#39;s purchase being independent of Toast. The lift value of 1.47 means that Toast&#39;s purchase lifts the Coffee&#39;s purchase by 1.47 times. . Therefore, we can conclude that there is indeed evidence to suggest that the purchase of Toast leads to the purchase of Coffee. The owner of the bakery &quot;The Bread Basket&quot; should consider bundling Toast and Cofee together as a Breakfast Set or Lunch Set, the staff in the store should also be trained to cross-sell Coffee to customers who purchase Toast, knowing that they are more likely to purchase them together, thereby increasing the store&#39;s revenue. . . Ending Note . So there you go, an MBA (Market Basket Analysis) done by an MBA (Master of Business Administration), no pun intended. Hope you enjoy reading it as much as I enjoyed writing and coding it. Feel free to keep in touch with me via my LinkedIn or GitHub Pages. . | . Credit: Me.me . . References . Chen, Y.L., Tang, K., Shen, R. J. &amp; Hu, Y. H. (2005). Market basket analysis in a multiple store environment. Decision Support Systems, 40(2), 339-354. | Farnham, P. G. (2014). Economics for Managers (3rd ed.). Essex, England: Pearson Education Limited. | Kaur, M. &amp; Kang, S. (2016). Market Basket Analysis: Identify the Changing Trends of Market Data Using Association Rule Mining. Procedia Computer Science, 85, 78-85. | Li, S. (2017, September 25), A Gentle Introduction on Market Basket Analysis — Association Rules. Towards Data Science. Retrieved from https://towardsdatascience.com/a-gentle-introduction-on-market-basket-analysis-association-rules-fa4b986a40ce | Moffitt, C. (2017, July 3). Introduction to Market Basket Analysis in Python. Practical Business Python. Retrieved from http://pbpython.com/market-basket-analysis.html | Rajaram, M. (2018, October 11). Market Basket Explained. Indium Software. Retrieved from https://indiumsoftware.com/blog/market-basket-explained/ | Wong, G. (2018, October 12). MBA For Breakfast or also known as the Market Basket Analysis. Towards Data Science. Retrieved from https://towardsdatascience.com/mba-for-breakfast-4c18164ef82b |",
            "url": "https://shlok2002.github.io/blog/2022/12/19/market-basket-analysis.html",
            "relUrl": "/2022/12/19/market-basket-analysis.html",
            "date": " • Dec 19, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Credit Cards",
            "content": "Introduction . Credit Cards work on the general principle of buy now and pay later. Apart from providing instant credit access, the cards also offer a host of other privileges, including cashback, reward points, discounts, and more. . When used wisely, credit cards can be a powerful financial asset. You can boost your credit score and other benefits by spending less daily. But if you are not financially disciplined, you tend to misuse your credit cards which leaves you in higher financial distress. Here are some common credit mistakes and tips on how to avoid them: . Making Late Payments . Paying your credit card debts late damages your credit score and may negatively impact your credit card issuer. A month’s late payment could reduce your credit card score by 100 points. Imagine you are late for three months or more. You also risk accumulating APR on your delinquent payments, increasing your debt profile. . . Set up autopay to ensure payments are always made on time. And if you don&#39;t prefer autopay, set calendar reminders and email notifications. Only Paying the Minimum Amount Due . Credit card issuers make it convenient to repay your balance by allowing minimum payments. However, paying more than the minimum amount is preferred when you can afford it. . Paying the minimum amount and revolving the credit to the next cycle can damage your finances like any missed or late payment. This is because interest is levied on the unpaid balance. When you pay only the minimum amount, the interest charges will be levied on the remaining balance. Paying the minimum can add more months — even years required to pay off your debt. . . Have a payment plan before you take on any bigger expenses, and always make consistent, on-time payments toward your balance. Not knowing your APR and applicable fees . When you apply and are approved for a credit card, you receive a long cardmember agreement that probably doesn’t top your must-read list. However, you must parse through the jargon and review important account terms to understand all the applicable fees. . Here are some key terms to look out for and what they mean: . Annual Fee: The yearly fee charged for holding a card. | Purchase APR: The annual percentage rate is the yearly interest rate purchases are charged when you carry a balance month-to-month Divide by 12 to get the monthly interest rate. | Late Payment Fee: The amount you are charged over and above the interest on the outstanding amount you owe for missing monthly payments. | Foreign Transaction Fee: Purchases made outside India often incur a fee, typically 2.5% - 3.5% per transaction. | Balance-Transfer Fee: When you transfer debt, you’ll often incur a 3% to 5% fee. | . Not Reviewing Your Account Statement . One common but easily avoidable mistake you can make on your credit card account is to overlook checking your account statement regularly. . Reviewing your credit card account periodically allows you to know the status of your account and prevent reporting or charging errors and potential frauds from taking advantage of your account. . If you cannot keep up with a weekly review, you should do a monthly account review to keep up with your bills and know the status of your account. . Having Too Many Credit Card Accounts . This might be a good idea in the short term because it gives you enough options to source lines of credit to cover your expenses. However, in the long run, what this means is that you will not be able to keep up with the accumulated debt on different credit card accounts. . These accounts will also charge APR, which means more debts. Also, when you apply for a new credit card, the card issuer may enquire about your credit cards, and too many inquiries may spook your existing lenders. . You can take advantage of Pre-qualification forms, which allow you to check if you qualify for a new credit card without damaging your credit score. . Taking Cash Advances . Taking out a cash advance is one of the costliest things you can do with your credit card. It may look like the most convenient way of getting some cash at your disposal, but it is also the most expensive one. . As soon as you withdraw the cash, the interest starts accruing on the amount withdrawn. Also, cash advances on credit cards attract an additional fee. Some banks charge a flat amount, while others charge a percentage of the amount withdrawn. . . For example, the cash advance fee on HDFC Regalia is 2.5% of the transaction amount. Maxing Out your Card . Using the majority, or all, of your available credit, is never a good idea. The amount of credit you use plays into your utilisation rate. The higher the utilisation rate, the lower your credit score. . If you frequently charge close to your monthly limit and have no problem paying off your bill, you can call the credit card company and ask for a credit increase. . . FAQs . What is APR? . The annual percentage rate (APR) refers to the yearly interest you pay on your borrowed amount to your credit card provider. . Who Issues Credit Scores in India? . The Reserve Bank of India has provided authorization to companies that have registered under The Credit Information Companies (Regulation) Act, 2005 to provide credit scores or ratings based on the past performances that have been reported by numerous member credit institutions and banks. CIBIL or Credit Information Bureau India Limited is India’s leading credit information bureau. .",
            "url": "https://shlok2002.github.io/blog/credit%20cards/finance/2022/12/16/Credit-Card.html",
            "relUrl": "/credit%20cards/finance/2022/12/16/Credit-Card.html",
            "date": " • Dec 16, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Using python to create a basic text editor",
            "content": "Background . Time spent thinking about doing something takes away the time you have to actually do it. . Having read the above words of advice on my Instagram feed, I decided to research interesting things to do when you have a lot of time to spend. I somewhat had an idea that I wanted to do something related to computers, maybe read about some new technology or try learning a new programming language. While browsing the internet, I came across an interesting YouTube video title “Python Project Create Real Software”. . I have been using python for scientific computing on Google Collaboratory for my university courses but have never had the opportunity to use this powerful language to create something. So keeping in mind the above quote, I jumped right into ‘creating’ this project. . I am writing this blog as an experience of mine and not a review per se. I appreciate the content creator for his efforts and give him full credit for the coding aspect of the project. . Pre-requisites: . Basic Knowledge of Python: Basic data structures like lists, tuples, dictionaries, etc. Some knowledge of tkinter - Graphical User Interface (GUI) package that is bundled with Python, Some experience with object oriented programming is beneficial but not necessary . | A very versatile text editor (ironic that one needs one to build one :D) like Visual Studio Code (VSC), Atom, Sublime or any editor of your choice. I personally prefer VSC since it has myriad extensions to make your life easy . | Willingness to learn something new, there are instances where it gets a bit repetitive while defining functionality for various features in the editor and one may feel the need to simply copy-paste those sections from the source code but do remember that doing so does hamper one’s learning . | . Features of the Text Editor: . A toolbar which houses the Bold, italic, alignment options and other basic text editing features . | A status bar for counting words and characters . | The new file, open, save, save-as, exit functionalities common to most applications. . | Multiple colour themes . | . Experience . I decided to name my text editor Brief , a name shared by a once-popular programmer’s text editor in the 1980s and early 1990s. . The prerequisite knowledge helped me in grasping the concepts explained in the video quite easily. The content delivered was simple and to the point with little to no shift from the main goal of the tutorial i.e. coding a text editor. In my personal opinion, a Python novice too can easily build this software with a bit of extra effort. . The great thing about this tutorial is that towards the end, the creator walks you through the process of taking the python script and converting it into a executable (.exe), which can be placed on your desktop and may replace a basic text editor. I would personally recommend using pyinstaller package rather than the cx_freeze package to make an executable. Pyinstaller is easier to use and does not requires a lot of effort. Just remember to use the correct flags to generate your desired outputs. . A few screenshots of the editor: . First screen . Dark Theme . . Scope for improvement . The bold, italic and underline buttons can have their functionality improved by incorporating selective highlighting. . | Functionality to add tables and charts in the editor. . | Functionality to export the .txt files to other extensions. . | . I thoroughly enjoyed coding the program and would be actively looking to code similar programs in the near future. I will share my experiences via this blog. . Resources . - Source Code . - Youtube Video . - Pyinstaller Package . - VSC Download . - My GitHub .",
            "url": "https://shlok2002.github.io/blog/python/software%20development/2022/12/12/Python-editor.html",
            "relUrl": "/python/software%20development/2022/12/12/Python-editor.html",
            "date": " • Dec 12, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://shlok2002.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://shlok2002.github.io/blog/2020/01/14/test-markdown-post.html",
            "relUrl": "/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I am an undergraduate student at Shiv Nadar Institution of Eminence majoring in electrical and electronics engineering. At university, I research modern machine learning algorithms for applications in content creation, finance, and energy analytics. I enjoy performing exploratory data analyses on public data sets and creating beautiful and intuitive visualisations. I am interested in leveraging the power of data to solve complex business problems in renewable energy and green finance. . I am an OUR candidate in the department of decison sciences, operations management and information systems, Shiv Nadar Institution of Eminence. I am advised by Dr.Satyam Mukherjee. My research focuses on the intersection of network sciences and data analytics with an emphasis on transportation networks and smart city research. . Outside academics, I am an F1 racing fan. I am intrigued by finance and think of myself as a long-term investor. I enjoy reading about a variety of topics. I am best reached by email at ks649@snu.edu.in. Feel free to reach out about my research or anything else I might be able to help with. For more details, check my CV1 . curriculum vitae &#8617; . |",
          "url": "https://shlok2002.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://shlok2002.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}